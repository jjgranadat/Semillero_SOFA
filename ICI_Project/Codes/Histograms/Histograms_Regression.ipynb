{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59be66b6-f376-484e-8c2b-c5d58a38c942",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Estimación de ICI mediante histogramas de diagramas de constelación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408abaa0-933f-499a-accc-5fe826ffcd58",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e5b55a-87f0-47ea-9a51-942c2216202b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 14:58:40.445320: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-14 14:58:40.447368: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-14 14:58:40.484596: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-14 14:58:40.485327: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-14 14:58:41.108677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sofa\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as ker\n",
    "import json\n",
    "import os\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras import models, regularizers, Sequential, utils\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from itertools import product\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1a2c2-572c-4fc4-8ba9-d4c6ad017cbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Funciones globales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f296da9-c4fc-485b-9231-e2d40c43a94e",
   "metadata": {},
   "source": [
    "### Extraer datos y calcular los histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b02dcfd1-b001-4072-9f6c-02ac61f5fe10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Special function to read the known data structure\n",
    "def read_data(folder_rx):\n",
    "    data = {}\n",
    "\n",
    "    # Read root directory\n",
    "    for folder in os.listdir(folder_rx):\n",
    "        # Check name consistency for subdirectories \n",
    "        if folder.endswith(\"spacing\"):\n",
    "            # Extract \"pretty\" part of the name\n",
    "            spacing = folder[:-8]\n",
    "            data[spacing] = {}\n",
    "            \n",
    "            # Read each data file\n",
    "            for file in os.listdir(f\"{folder_rx}/{folder}\"):\n",
    "                # Check name consistency for data files\n",
    "                if file.find(\"consY\") != -1:\n",
    "                    # Extract \"pretty\" part of the name\n",
    "                    osnr = file.split(\"_\")[2][5:-4]\n",
    "                    \n",
    "                    # Initialize if not created yet\n",
    "                    if data[spacing].get(osnr) == None:\n",
    "                        data[spacing][osnr] = {}\n",
    "                    # Set data\n",
    "                    csv_file_data = pl.read_csv(f\"{folder_rx}/{folder}/{file}\")\n",
    "                    data[spacing][osnr] = csv_file_data\n",
    "    return data\n",
    "\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return np.array([a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n)])\n",
    "\n",
    "def plot_constellation_diagram(X, ax):\n",
    "    ax.scatter(X.real, X.imag, alpha=0.5)\n",
    "    ax.set_title(\"Constellation diagram\")\n",
    "    ax.set_xlabel(\"I\")\n",
    "    ax.set_ylabel(\"Q\")\n",
    "    \n",
    "def calculate_gmm(data, gm_kwargs):\n",
    "    return GaussianMixture(**gm_kwargs).fit(data)\n",
    "    \n",
    "def calculate_1d_histogram(X, bins):\n",
    "    hist_y, hist_x = np.histogram(X.real, bins=bins)\n",
    "    # Remove last bin edge\n",
    "    hist_x = hist_x[:-1]\n",
    "    \n",
    "    return hist_x, hist_y\n",
    "\n",
    "def plot_1d_histogram(X, ax):\n",
    "    ax.hist(X, bins=bins, density=True, alpha=0.5, label=\"Calculated histogram\")\n",
    "    \n",
    "def plot_gmm_1d(gm, limits):\n",
    "    x = np.linspace(*limits, 1000)\n",
    "    \n",
    "    logprob = gm.score_samples(x.reshape(-1, 1))\n",
    "    responsibilities = gm.predict_proba(x.reshape(-1, 1))\n",
    "    pdf = np.exp(logprob)\n",
    "    pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "    \n",
    "    ax.plot(x, pdf_individual, '--', label=\"Adjusted histogram\")\n",
    "\n",
    "def plot_gmm_2d(gm, limits, ax):\n",
    "    x = y = np.linspace(*limits)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = -gm.score_samples(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)\n",
    "\n",
    "    ax.contour(\n",
    "        X, Y, Z,\n",
    "        norm=LogNorm(vmin=1.0, vmax=1000.0), \n",
    "        levels=np.logspace(0, 3, 25), cmap=\"seismic\"\n",
    "    )\n",
    "    \n",
    "def calculate_3d_histogram(X, bins, limits, spacing, snr):\n",
    "    hist, xedges, yedges = np.histogram2d(X.real, X.imag, bins=bins, range=[[*limits], [*limits]])\n",
    "\n",
    "    # Define the extent\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "    # Create the meshgrid for the surface plot, excluding the last edge\n",
    "    x_mesh, y_mesh = np.meshgrid(xedges[:-1], yedges[:-1])\n",
    "    \n",
    "    return hist, x_mesh, y_mesh\n",
    "    \n",
    "def plot_3d_histogram(x_mesh, y_mesh, hist, ax):\n",
    "    ax.plot_surface(x_mesh, y_mesh, hist.T, cmap=\"seismic\", rstride=1, cstride=1, edgecolor=\"none\")\n",
    "    ax.set_title(\"3D Histogram\")\n",
    "    ax.set_xlabel(\"I\")\n",
    "    ax.set_ylabel(\"Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a9c57-8656-4e43-a1d2-c1da52a92928",
   "metadata": {},
   "source": [
    "### Regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5dd6092-f808-4326-af60-1b750a5710fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_once(varname, fn, args):\n",
    "    \"\"\" Calculate a variable only once. \"\"\"\n",
    "    if varname not in globals():\n",
    "        return fn(**args)\n",
    "    return eval(varname)\n",
    "\n",
    "\n",
    "def estimation_model(\n",
    "    layers_props_lst: list, loss_fn: ker.losses.Loss, input_dim: int\n",
    ") -> ker.models.Sequential:\n",
    "    \"\"\" Compile a sequential model for regression purposes. \"\"\"\n",
    "    model = ker.Sequential()\n",
    "    # Hidden layers\n",
    "    for i, layer_props in enumerate(layers_props_lst):\n",
    "        if i == 0:\n",
    "            model.add(ker.layers.Dense(input_dim=input_dim, **layer_props))\n",
    "        else:\n",
    "            model.add(ker.layers.Dense(**layer_props))\n",
    "    # Regressor\n",
    "    model.add(ker.layers.Dense(units=1, activation=\"linear\"))\n",
    "    \n",
    "    model.compile(loss=loss_fn, optimizer=\"adam\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def estimation_crossvalidation(X, y, n_splits, layer_props, loss_fn, callbacks):\n",
    "    \"\"\" Crossvalidation of an estimation network. \"\"\"\n",
    "    # Scores dict\n",
    "    scores = {}\n",
    "    scores[\"model\"] = []\n",
    "    scores[\"loss\"] = []\n",
    "    scores[\"mae\"] = {\"train\": [], \"test\": []}\n",
    "    scores[\"r2\"] = {\"train\": [], \"test\": []}\n",
    "    scores[\"rmse\"] = {\"train\": [], \"test\": []}\n",
    "    \n",
    "    # K-fold crossvalidation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Input variables standarizer\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test_kf = sc.transform(X_test)\n",
    "\n",
    "        model = estimation_model(layer_props, loss_fn, X_train.shape[1])\n",
    "        \n",
    "        # Save test scalar loss\n",
    "        if callbacks:\n",
    "            loss = model.fit(\n",
    "                X_train, y_train, epochs=5000, batch_size=64, callbacks=callbacks, verbose=0\n",
    "            )\n",
    "        else:\n",
    "            loss = model.fit(X_train, y_train, epochs=5000, batch_size=64, verbose=0)\n",
    "        print(f\"Needed iterations: {len(loss.history['loss'])}\")\n",
    "        loss = loss.history[\"loss\"]\n",
    "        \n",
    "        # Predict using train values\n",
    "        predictions_train = model.predict(X_train, verbose=0)\n",
    "        # Predict using test values\n",
    "        predictions_test = model.predict(X_test_kf, verbose=0)\n",
    "\n",
    "        # Dataframe for better visualization\n",
    "        train_data_train = pl.DataFrame(\n",
    "            {\"ICI\": [y_train], \"Predicted ICI\": [predictions_train]}\n",
    "        )\n",
    "        train_data_test = pl.DataFrame(\n",
    "            {\"ICI\": [y_test], \"Predicted ICI\": [predictions_test]}\n",
    "        )\n",
    "\n",
    "        # MAE\n",
    "        mae_score_train = mean_absolute_error(\n",
    "            *train_data_train[\"ICI\"], *train_data_train[\"Predicted ICI\"]\n",
    "        )\n",
    "        mae_score_test = mean_absolute_error(\n",
    "            *train_data_test[\"ICI\"], *train_data_test[\"Predicted ICI\"]\n",
    "        )\n",
    "\n",
    "        # R²\n",
    "        r2_score_train = r2_score(\n",
    "            *train_data_train[\"ICI\"], *train_data_train[\"Predicted ICI\"]\n",
    "        )\n",
    "        r2_score_test = r2_score(\n",
    "            *train_data_test[\"ICI\"], *train_data_test[\"Predicted ICI\"]\n",
    "        )\n",
    "         \n",
    "        # RMSE\n",
    "        rmse_score_train = mean_squared_error(\n",
    "            *train_data_train[\"ICI\"], *train_data_train[\"Predicted ICI\"],\n",
    "            squared=False\n",
    "        )\n",
    "        rmse_score_test = mean_squared_error(\n",
    "            *train_data_test[\"ICI\"], *train_data_test[\"Predicted ICI\"],\n",
    "            squared=False\n",
    "        )\n",
    "\n",
    "        # Append to lists\n",
    "        scores[\"model\"].append(model)\n",
    "        scores[\"loss\"].append(loss)\n",
    "        scores[\"mae\"][\"train\"].append(mae_score_train)\n",
    "        scores[\"mae\"][\"test\"].append(mae_score_test)\n",
    "        scores[\"r2\"][\"train\"].append(r2_score_train)\n",
    "        scores[\"r2\"][\"test\"].append(r2_score_test)\n",
    "        scores[\"rmse\"][\"train\"].append(rmse_score_train)\n",
    "        scores[\"rmse\"][\"test\"].append(rmse_score_test)\n",
    "        \n",
    "    return scores\n",
    "\n",
    "\n",
    "def test_estimation_model(data, n_splits, max_neurons, activations, \n",
    "                          use_osnr=True, loss_fn=\"mean_absolute_error\"):\n",
    "    \"\"\" Test a spectral spacing estimation model with given parameters. \"\"\"\n",
    "    var_n = 97 if use_osnr else 96\n",
    "\n",
    "    # Split variables\n",
    "    # Variables\n",
    "    X = np.array(data[:, 0:var_n])\n",
    "    # Tags\n",
    "    y = np.array(data[:, -1])\n",
    "    \n",
    "    # Layer properties\n",
    "    layer_props = [\n",
    "        {\"units\": max_neurons // (2**i), \"activation\": activation}\n",
    "        for i, activation in enumerate(activations)\n",
    "    ]\n",
    "    print(f\"{layer_props}{' + OSNR' if use_osnr else ''}\")\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"loss\", patience=30, mode=\"min\", restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    return estimation_crossvalidation(X, y, n_splits, layer_props, loss_fn, callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db460db-db03-416b-9dbe-aa3d06c5273b",
   "metadata": {},
   "source": [
    "### Graficar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bcc7b0-f358-4feb-ab6f-740f93fa0a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss(score, end=500):\n",
    "    \"\"\" Plot loss evolution for each k-fold. \"\"\"\n",
    "    for k, loss in enumerate(score[\"loss\"]):\n",
    "        loss_length = len(loss.history[\"loss\"])\n",
    "        loss_values = loss.history[\"loss\"][:end if loss_length > end else loss_length]\n",
    "        epoch_values = range(end if loss_length > end else loss_length)\n",
    "        plt.plot(epoch_values, loss_values, label=f\"k = {k+1}\")\n",
    "\n",
    "        \n",
    "def plot_losses(scores, scenario, cmp_fn, cmp_values=[], end=500, based_on_index=False):\n",
    "    \"\"\" Plot loss graphics for each scenario. \"\"\"\n",
    "    # Handle default cmp_values\n",
    "    if len(cmp_values) == 0:\n",
    "        cmp_values = np.zeros(len(scores))\n",
    "        \n",
    "    fig_loss = plt.figure(figsize=(16, 3*len(scores)), layout=\"constrained\")\n",
    "    fig_loss.suptitle(f\"{scenario} loss history\", size=\"x-large\")\n",
    "    \n",
    "    for index, (score, cmps) in enumerate(zip(scores, cmp_values)):\n",
    "        plt.subplot(len(scores)//2, 2, index + 1)\n",
    "        plot_loss(score, end=end)\n",
    "        \n",
    "        plt.title(cmp_fn(cmps) if not based_on_index else cmp_fn(index))\n",
    "        \n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        \n",
    "        # Transparent white box black edge legend\n",
    "        legend = plt.legend(loc=\"upper right\", edgecolor=\"black\")\n",
    "        legend.get_frame().set_alpha(None)\n",
    "        legend.get_frame().set_facecolor((1, 1, 1, 0.01))\n",
    "        \n",
    "        plt.grid(True)\n",
    "\n",
    "def plot_scores(scores, x_values, scenario, score_names, data_type,\n",
    "                label, xlabel, markers=[], colors=[], based_on_index=False,\n",
    "                log=False, multiple_points=False, plot_train=True):\n",
    "    fig_scores = plt.figure(figsize=(16, 6), layout=\"constrained\")\n",
    "    fig_scores.suptitle(f\"{scenario} scores\")\n",
    "    i = 0\n",
    "    for sn in score_names:\n",
    "        ax = plt.subplot(1, len(score_names), i+1)\n",
    "        for dt in data_type:\n",
    "            if not plot_train and dt == \"train\":\n",
    "                continue\n",
    "            points = [np.average(score[sn][dt]) for score in scores]\n",
    "            if not multiple_points:\n",
    "                label_value = \"\"\n",
    "                plt.scatter(x_values, points, marker=markers[0 if dt == \"train\" else 1],\n",
    "                            label=f\"{dt.title()} {label(i)}\", s=100)\n",
    "            else:\n",
    "                label_value = \"\"\n",
    "                points1 = points[::2]\n",
    "                points2 = points[1::2]\n",
    "                plt.scatter(x_values, points1, marker=markers[0 if dt == \"train\" else 1],\n",
    "                            color=colors[0 if dt == \"train\" else 1],\n",
    "                            label=f\"{dt.title()} {label(0)}\", s=100)\n",
    "                plt.scatter(x_values, points2, marker=markers[2 if dt == \"train\" else 3],\n",
    "                            color=colors[2 if dt == \"train\" else 3],\n",
    "                            label=f\"{dt.title()} {label(1)}\", s=100)\n",
    "            title = \"\"\n",
    "            if sn == \"r2\":\n",
    "                title = \"R²\"\n",
    "            elif sn == \"acc\":\n",
    "                title = \"Accuracy\"\n",
    "            else:\n",
    "                title = sn.upper()\n",
    "            plt.title(title)\n",
    "                \n",
    "        plt.xlabel(xlabel)\n",
    "        # Adjust logarithmic scale if requested\n",
    "        if log:\n",
    "            plt.xscale(\"log\", base=2)\n",
    "            \n",
    "        # Make integer xticks if matches}\n",
    "        if type(x_values[0]) == np.int64:\n",
    "            ax.set_xticks(x_values)\n",
    "            \n",
    "        if type(x_values[0]) == str:\n",
    "            ax.set_xticks(range(len(x_values)), x_values)\n",
    "            \n",
    "        # Shrink current axis by 20%\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "        # Transparent white box black edge legend\n",
    "        legend = plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5),\n",
    "                            edgecolor=\"black\")\n",
    "        legend.get_frame().set_alpha(None)\n",
    "        legend.get_frame().set_facecolor((1, 1, 1, 0.01))\n",
    "\n",
    "        plt.grid(True)\n",
    "        i += 1\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_cm(scores, interval_lst):\n",
    "    CM = np.array(scores.get(\"cm\").get(\"test\"))\n",
    "    for n, interval in enumerate(interval_lst):\n",
    "        result = np.zeros(CM[0][0].shape)\n",
    "        for cm in CM:\n",
    "            result = np.add(result, cm[n])\n",
    "        result /= np.sum(result)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=result, display_labels=[\"Positive\", \"Negative\"])\n",
    "        disp.plot(colorbar=False)\n",
    "        lower_limit, upper_limit = interval \n",
    "        plt.title(f\"Confusion matrix for class from {lower_limit} GHz up to {upper_limit} GHz\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7bcd59-a733-450f-8a13-5cb88e231038",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Restaurar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79d9ed4-d062-4c71-ba0e-4cfa1704482d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r histograms_hist\n",
    "%store -r histograms_gmm\n",
    "histograms = (histograms_hist, histograms_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efce4fa-5de8-4a54-8685-491ecc648041",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Leer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d361a4-bc88-451a-9945-c05e8b3a17ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_tx = \"../../../Demodulation/Data/Processed/2x16QAM_16GBd.csv\"\n",
    "folder_rx = \"../../../Demodulation/Data/Processed\"\n",
    "\n",
    "# Transmitted data\n",
    "X_tx = np.array(pl.read_csv(file_tx))\n",
    "X_txs = split(X_tx, 12)\n",
    "\n",
    "# Read received data\n",
    "data = read_data(folder_rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b3c94-9896-4f2d-ac62-4e16a65274c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Obtener histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b0a6a99-4b60-424f-87dc-c482366b25e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'histograms_hist' (dict)\n",
      "Stored 'histograms_gmm' (dict)\n"
     ]
    }
   ],
   "source": [
    "def get_histograms():\n",
    "    spacings = [\"15\", \"15.5\", \"16\", \"16.5\", \"17\", \"17.6\", \"18\"]\n",
    "\n",
    "    histograms_hist = defaultdict(lambda: defaultdict(list))\n",
    "    histograms_gmm = defaultdict(lambda: defaultdict(list)) \n",
    "    bins = 128\n",
    "    limits = [-5, 5]\n",
    "\n",
    "    for spacing in spacings:\n",
    "        X_rx = data[f\"{spacing}GHz\"]\n",
    "        for snr in X_rx:\n",
    "            # Extract data \n",
    "            X_ch = np.array(X_rx[snr])\n",
    "            X_ch = X_ch[:, 0] + 1j*X_ch[:, 1]\n",
    "\n",
    "            X_chs = split(X_ch, 12)\n",
    "\n",
    "            for n, x_ch in enumerate(X_chs):\n",
    "                # Calculate 2D GMM\n",
    "                input_data = np.vstack((x_ch.real, x_ch.imag)).T\n",
    "                gm_kwargs = {\n",
    "                    \"means_init\": np.array(list(product([-3, -1, 1, 3], repeat=2))), \n",
    "                    \"n_components\": 16\n",
    "                }\n",
    "                gm_2d = calculate_gmm(input_data, gm_kwargs)\n",
    "\n",
    "                # Calculate 3D histogram\n",
    "                hist, x_mesh, y_mesh = calculate_3d_histogram(x_ch, bins, limits, spacing, snr)\n",
    "\n",
    "                # Save 3D histogram\n",
    "                histograms_hist[f\"{spacing}GHz\"][snr].append(hist)\n",
    "\n",
    "                # Calculate I and Q histograms\n",
    "                hist_x, hist_y = calculate_1d_histogram(x_ch.real, bins)\n",
    "                input_data = np.repeat(hist_x, hist_y).reshape(-1, 1)\n",
    "                gm_kwargs = {\n",
    "                    \"means_init\": np.array([-3, -1, 1, 3]).reshape(4, 1), \n",
    "                    \"n_components\": 4\n",
    "                }\n",
    "                gm_i = calculate_gmm(input_data, gm_kwargs)\n",
    "\n",
    "                # Q\n",
    "                hist_x, hist_y = calculate_1d_histogram(x_ch.imag, bins)\n",
    "                input_data = np.repeat(hist_x, hist_y).reshape(-1, 1)\n",
    "                gm_kwargs = {\n",
    "                    \"means_init\": np.array([-3, -1, 1, 3]).reshape(4, 1), \n",
    "                    \"n_components\": 4\n",
    "                }\n",
    "                gm_q = calculate_gmm(input_data, gm_kwargs)\n",
    "\n",
    "                # Save gaussians\n",
    "                histograms_gmm[f\"{spacing}GHz\"][snr].append([gm_2d, gm_i, gm_q])\n",
    "\n",
    "    histograms_hist = dict(histograms_hist)\n",
    "    histograms_gmm = dict(histograms_gmm)\n",
    "    return histograms_hist, histograms_gmm\n",
    "\n",
    "histograms = calc_once(\"histograms\", get_histograms, {})\n",
    "histograms_hist, histograms_gmm = histograms\n",
    "%store histograms_hist\n",
    "%store histograms_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8dedd46-4b31-44de-a82b-438db4fb61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms():\n",
    "    spacings = [\"15\", \"15.5\", \"16\", \"16.5\", \"17\", \"17.6\", \"18\"]\n",
    "    bins = 128\n",
    "    limits = [-5, 5]\n",
    "    \n",
    "    for spacing in spacings:\n",
    "        X_rx = data[f\"{spacing}GHz\"]\n",
    "        for snr in X_rx:\n",
    "            # Extract data \n",
    "            X_ch = np.array(X_rx[snr])\n",
    "            X_ch = X_ch[:, 0] + 1j*X_ch[:, 1]\n",
    "    \n",
    "            plt.figure(figsize=(12, 12), layout=\"tight\")\n",
    "    \n",
    "            # Plot constellation diagram\n",
    "            ax = plt.subplot(2, 2, 1)\n",
    "            plot_constellation_diagram(X_ch, ax)\n",
    "            \n",
    "            gm_2d = histograms_gmm.get(f\"{spacing}GHz\").get(snr)[0]\n",
    "            \n",
    "            # Plot 2D GMM\n",
    "            plot_gmm_2d(gm_2d, limits, ax)\n",
    "            ax.grid(True)\n",
    "    \n",
    "            # Calculate 3D histogram\n",
    "            hist, x_mesh, y_mesh = calculate_3d_histogram(X_ch, bins, limits, spacing, snr)\n",
    "            \n",
    "            # Plot 3D histogram\n",
    "            ax = plt.subplot(2, 2, 2, projection=\"3d\")\n",
    "            plot_3d_histogram(x_mesh, y_mesh, hist, ax)\n",
    "    \n",
    "            # Plot I and Q histograms separately\n",
    "            # I\n",
    "            ax = plt.subplot(2, 2, 3)\n",
    "            plot_1d_histogram(X_ch.real, ax)\n",
    "            \n",
    "            hist_x, hist_y = calculate_1d_histogram(X_ch.real, bins)\n",
    "            input_data = np.repeat(hist_x, hist_y).reshape(-1, 1)\n",
    "            gm_kwargs = {\n",
    "                \"means_init\": np.array([-3, -1, 1, 3]).reshape(4, 1), \n",
    "                \"n_components\": 4\n",
    "            }\n",
    "            gm_i = calculate_gmm(input_data, gm_kwargs)\n",
    "            plot_gmm_1d(gm_i, limits)\n",
    "    \n",
    "            ax.set_title(\"I-Histogram\")\n",
    "            ax.set_xlabel(\"I\")\n",
    "            ax.grid(True)\n",
    "    \n",
    "            # Q\n",
    "            ax = plt.subplot(2, 2, 4)\n",
    "            plot_1d_histogram(X_ch.imag, ax)\n",
    "            \n",
    "            hist_x, hist_y = calculate_1d_histogram(X_ch.imag, bins)\n",
    "            input_data = np.repeat(hist_x, hist_y).reshape(-1, 1)\n",
    "            gm_kwargs = {\n",
    "                \"means_init\": np.array([-3, -1, 1, 3]).reshape(4, 1), \n",
    "                \"n_components\": 4\n",
    "            }\n",
    "            gm_q = calculate_gmm(input_data, gm_kwargs)\n",
    "            plot_gmm_1d(gm_q, limits)\n",
    "            ax.set_title(\"Q-Histogram\")\n",
    "            ax.set_xlabel(\"Q\")\n",
    "            ax.grid(True)\n",
    "        \n",
    "            plt.suptitle(f\"Plots for {snr} OSNR and {spacing}GHz of spacing\")\n",
    "    \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f3c52-2f24-4206-a56a-4887d5f001e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc4ceb73-290b-430c-b5e3-7ed4b544b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (840, 98)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬──────────┬───────┬───────┐\n",
      "│ col0      ┆ col1      ┆ col2      ┆ col3      ┆ … ┆ col94     ┆ col95    ┆ col96 ┆ col97 │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---      ┆ ---   ┆ ---   │\n",
      "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64      ┆ f64   ┆ f64   │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪══════════╪═══════╪═══════╡\n",
      "│ -2.726003 ┆ -2.822036 ┆ -2.743914 ┆ -0.906839 ┆ … ┆ 0.006134  ┆ 0.247726 ┆ 23.0  ┆ 15.0  │\n",
      "│ -2.707006 ┆ -2.735225 ┆ -2.773898 ┆ -0.827666 ┆ … ┆ -0.010791 ┆ 0.240321 ┆ 23.0  ┆ 15.0  │\n",
      "│ -2.636324 ┆ -2.79119  ┆ -2.814175 ┆ -0.921746 ┆ … ┆ -0.014103 ┆ 0.244062 ┆ 23.0  ┆ 15.0  │\n",
      "│ -2.735143 ┆ -2.759209 ┆ -2.714546 ┆ -0.934065 ┆ … ┆ 0.01472   ┆ 0.283967 ┆ 23.0  ┆ 15.0  │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …        ┆ …     ┆ …     │\n",
      "│ -2.685825 ┆ -2.698239 ┆ -2.743573 ┆ -0.789322 ┆ … ┆ -0.002169 ┆ 0.050983 ┆ 40.0  ┆ 18.0  │\n",
      "│ -2.692841 ┆ -2.694913 ┆ -2.727602 ┆ -0.776764 ┆ … ┆ 0.00253   ┆ 0.048473 ┆ 40.0  ┆ 18.0  │\n",
      "│ -2.695651 ┆ -2.697755 ┆ -2.747918 ┆ -0.788175 ┆ … ┆ 0.000416  ┆ 0.052023 ┆ 40.0  ┆ 18.0  │\n",
      "│ -2.709551 ┆ -2.702334 ┆ -2.757617 ┆ -0.798066 ┆ … ┆ 0.002603  ┆ 0.048269 ┆ 40.0  ┆ 18.0  │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴──────────┴───────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Dataframe con 98 columnas\n",
    "# 16 primeras para las medias\n",
    "# 64 siguientes para los valores de las matrices de covarianza\n",
    "# Penúltima para el valor del OSNR (dB)\n",
    "# Última para el valor del espaciamiento (GHz)\n",
    "\n",
    "df_dict = {f\"col{n}\": [] for n in range(98)}\n",
    "data_list = []\n",
    "\n",
    "# Iterate over the dictionary and populate the DataFrame\n",
    "for spacing, osnr_dict in histograms_gmm.items():\n",
    "    for osnr, gmm_list in osnr_dict.items():\n",
    "        for n in range(12):\n",
    "            gmm_2d = gmm_list[n][0]\n",
    "            means = gmm_2d.means_.flatten()\n",
    "            covariances = gmm_2d.covariances_.flatten()\n",
    "            osnr_value = np.array([float(osnr[:-2])])\n",
    "            spacing_value = np.array([float(spacing[:-3])])\n",
    "\n",
    "            features = np.concatenate((means, covariances, osnr_value, spacing_value))\n",
    "            row_dict = {f\"col{n}\": feature for n, feature in enumerate(features)}\n",
    "            data_list.append(row_dict)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df = pl.DataFrame(data_list)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "df.write_json(\"histograms.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7171c0b-812c-4e54-b46b-91480904a9a4",
   "metadata": {},
   "source": [
    "## Evaluación de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffca2c3-15d4-4d50-bbe3-44fa538e51cb",
   "metadata": {},
   "source": [
    "Se evaluará una combinación de parámetros:\n",
    "- Número de neuronas máximas por capa (16, 64, 256, 1024)\n",
    "- Número de capas (1, 2, 3)\n",
    "- Combinación de funciones de activación (ReLu, tanh, sigmoid)\n",
    "\n",
    "Los resultados tendrán la siguiente estructura:\n",
    "```\n",
    "{\"xyz\": {\"n_neurons\": {\"osnr/wo_osnr\": results}}}\n",
    "```\n",
    "Donde xyz serán las iniciales de las combinaciones de funciones de activación, n_neurons será el número de neuronas máximo, osnr/wo_osnr será la indicación de si se usó o no el OSNR como característica y results será el objeto resultante que contiene todos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27927d24-4ad8-4a25-b63d-dd5e54dfc0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['relu'],\n",
       " ['tanh'],\n",
       " ['sigmoid'],\n",
       " ['relu', 'relu'],\n",
       " ['relu', 'tanh'],\n",
       " ['relu', 'sigmoid'],\n",
       " ['tanh', 'relu'],\n",
       " ['tanh', 'tanh'],\n",
       " ['tanh', 'sigmoid'],\n",
       " ['sigmoid', 'relu'],\n",
       " ['sigmoid', 'tanh'],\n",
       " ['sigmoid', 'sigmoid'],\n",
       " ['relu', 'relu', 'relu'],\n",
       " ['relu', 'relu', 'tanh'],\n",
       " ['relu', 'relu', 'sigmoid'],\n",
       " ['relu', 'tanh', 'relu'],\n",
       " ['relu', 'tanh', 'tanh'],\n",
       " ['relu', 'tanh', 'sigmoid'],\n",
       " ['relu', 'sigmoid', 'relu'],\n",
       " ['relu', 'sigmoid', 'tanh'],\n",
       " ['relu', 'sigmoid', 'sigmoid'],\n",
       " ['tanh', 'relu', 'relu'],\n",
       " ['tanh', 'relu', 'tanh'],\n",
       " ['tanh', 'relu', 'sigmoid'],\n",
       " ['tanh', 'tanh', 'relu'],\n",
       " ['tanh', 'tanh', 'tanh'],\n",
       " ['tanh', 'tanh', 'sigmoid'],\n",
       " ['tanh', 'sigmoid', 'relu'],\n",
       " ['tanh', 'sigmoid', 'tanh'],\n",
       " ['tanh', 'sigmoid', 'sigmoid'],\n",
       " ['sigmoid', 'relu', 'relu'],\n",
       " ['sigmoid', 'relu', 'tanh'],\n",
       " ['sigmoid', 'relu', 'sigmoid'],\n",
       " ['sigmoid', 'tanh', 'relu'],\n",
       " ['sigmoid', 'tanh', 'tanh'],\n",
       " ['sigmoid', 'tanh', 'sigmoid'],\n",
       " ['sigmoid', 'sigmoid', 'relu'],\n",
       " ['sigmoid', 'sigmoid', 'tanh'],\n",
       " ['sigmoid', 'sigmoid', 'sigmoid']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osnr_lst = [\"osnr\", \"wo_osnr\"]\n",
    "max_neurons = [str(2**n) for n in range(3, 11)]\n",
    "functs = [\"relu\", \"tanh\", \"sigmoid\"]\n",
    "layers_n = [1, 2, 3]\n",
    "\n",
    "combinations = [\n",
    "    [list(subset) for subset in product(functs, repeat=n)]\n",
    "    for n in layers_n\n",
    "]\n",
    "\n",
    "hidden_layers = [item for sublist in combinations for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29e306-cde9-4113-924a-ec3bd07e0d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'units': 64, 'activation': 'sigmoid'}, {'units': 32, 'activation': 'sigmoid'}] + OSNR\n",
      "Needed iterations: 856\n",
      "Needed iterations: 837\n",
      "Needed iterations: 581\n",
      "Needed iterations: 638\n",
      "Needed iterations: 1018\n",
      "Saving results...\n",
      "Results saved!\n",
      "[{'units': 64, 'activation': 'sigmoid'}, {'units': 32, 'activation': 'sigmoid'}]\n",
      "Needed iterations: 514\n",
      "Needed iterations: 771\n",
      "Needed iterations: 603\n",
      "Needed iterations: 708\n",
      "Needed iterations: 883\n",
      "Saving results...\n",
      "Results saved!\n",
      "[{'units': 128, 'activation': 'sigmoid'}, {'units': 64, 'activation': 'sigmoid'}] + OSNR\n",
      "Needed iterations: 466\n",
      "Needed iterations: 608\n",
      "Needed iterations: 538\n",
      "Needed iterations: 633\n",
      "Needed iterations: 654\n",
      "Saving results...\n",
      "Results saved!\n",
      "[{'units': 128, 'activation': 'sigmoid'}, {'units': 64, 'activation': 'sigmoid'}]\n",
      "Needed iterations: 798\n",
      "Needed iterations: 519\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    histograms_reg_results = sofa.load_hdf5(\"histograms_reg_results.h5\")\n",
    "except:\n",
    "    print(\"Error loading from file, creating a new dictionary\")\n",
    "    histograms_reg_results = defaultdict(defaultdict(defaultdict(defaultdict().copy).copy).copy)\n",
    "\n",
    "# Evaluar\n",
    "for activations in hidden_layers:\n",
    "    for neurons in max_neurons:\n",
    "        for osnr in osnr_lst:\n",
    "            args = {\"data\": df, \"n_splits\": 5, \"max_neurons\": int(neurons), \"activations\": activations, \"use_osnr\": True if osnr == \"osnr\" else False}\n",
    "            act_fn_name = \"\".join([s[0] for s in activations])\n",
    "            if histograms_reg_results[act_fn_name][neurons][osnr] == defaultdict(): \n",
    "                # Get results\n",
    "                results = test_estimation_model(**args)\n",
    "                # Serialize model\n",
    "                results[\"model\"] = [utils.serialize_keras_object(model) for model in results[\"model\"]]\n",
    "                # Save serialized model for serialization\n",
    "                histograms_reg_results[act_fn_name][neurons][osnr] = results\n",
    "                # Save results with serialized model\n",
    "                print(\"Saving results...\")\n",
    "                sofa.save_hdf5(histograms_reg_results, \"histograms_reg_results.h5\")\n",
    "                print(\"Results saved!\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730b856-22ee-4351-bd1f-44a3cf49735b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd = defaultdict(defaultdict(defaultdict().copy).copy)\n",
    "dd[\"r\"][\"1024\"]\n",
    "#histograms_reg_results[\"rr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91445933-554a-4ff9-a694-8352380b19ae",
   "metadata": {},
   "source": [
    "## Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e37227-a860-4b01-9db7-45a8b1d86ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_n = [2, 3, 4, 5, 6, 7]\n",
    "OSNR = [\"\", \"_woOSNR\"]\n",
    "classes_scores = {f\"scores_histograms{osnr}\":\n",
    "                  [np.average(\n",
    "                      eval(f\"scores_histograms_{n}classes{osnr}\").get(\n",
    "                          \"acc\"\n",
    "                      ).get(\n",
    "                          \"test\"\n",
    "                      )\n",
    "                  ) for n in classes_n]\n",
    "                  for osnr in OSNR\n",
    "                 }\n",
    "plt.figure(figsize=(8, 6), layout=\"constrained\")\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "for osnr in OSNR:\n",
    "    OSNR_label = \" with OSNR\" if osnr == \"\" else \" without OSNR\"\n",
    "    marker = \"8\"\n",
    "    plt.plot(classes_n, classes_scores.get(f\"scores_histograms{osnr}\"),\n",
    "             marker=marker, linestyle=\"--\",\n",
    "             label=OSNR_label)\n",
    "plt.xlabel(\"Number of classes\")\n",
    "ax.set_xticks(classes_n)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Transparent white box black edge legend\n",
    "legend = plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5),\n",
    "                    edgecolor=\"black\")\n",
    "legend.get_frame().set_alpha(None)\n",
    "legend.get_frame().set_facecolor((1, 1, 1, 0.01))\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(\"hist_classes.svg\", format=\"svg\", transparent=True, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16de46d-eb8b-4375-8e6a-16bbb8fe4034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
