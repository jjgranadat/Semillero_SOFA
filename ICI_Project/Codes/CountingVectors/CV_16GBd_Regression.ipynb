{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "59be66b6-f376-484e-8c2b-c5d58a38c942",
      "metadata": {
        "tags": [],
        "id": "59be66b6-f376-484e-8c2b-c5d58a38c942"
      },
      "source": [
        "# Estimación de ICI mediante *counting vectors* a 16 GBd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialización"
      ],
      "metadata": {
        "id": "pJ6XTcEno0ID"
      },
      "id": "pJ6XTcEno0ID"
    },
    {
      "cell_type": "markdown",
      "id": "408abaa0-933f-499a-accc-5fe826ffcd58",
      "metadata": {
        "id": "408abaa0-933f-499a-accc-5fe826ffcd58"
      },
      "source": [
        "### Librerías\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive\n",
        "    GOOGLE_COLAB = True\n",
        "    ROOT = \"/content/drive/MyDrive/SOFA/ICI_Project\"\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    !cp {ROOT}\"/sofa.py\" \".\"\n",
        "    !cp {ROOT}\"/counting_vectors_16f.csv\" \".\"\n",
        "    !cp {ROOT}\"/counting_vectors_16g.csv\" \".\"\n",
        "else:\n",
        "    GOOGLE_COLAB = False\n",
        "    ROOT = \".\""
      ],
      "metadata": {
        "id": "0k-2EzDZazUP",
        "outputId": "b59cb57b-e7af-4fa5-9b19-dcb8cc5f32ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0k-2EzDZazUP",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c7e5b55a-87f0-47ea-9a51-942c2216202b",
      "metadata": {
        "tags": [],
        "id": "c7e5b55a-87f0-47ea-9a51-942c2216202b"
      },
      "outputs": [],
      "source": [
        "import sofa\n",
        "\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as ker\n",
        "import json\n",
        "import os\n",
        "\n",
        "from scipy.stats import multivariate_normal\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_validate, KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from tensorflow.keras import models, regularizers, Sequential, utils\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from itertools import product\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPU = tf.config.list_physical_devices('GPU')\n",
        "if len(GPU) > 0:\n",
        "    print(f\"Using GPU: {GPU}\")"
      ],
      "metadata": {
        "id": "ObdMXuCIlLXR",
        "outputId": "dcbe8cc2-1776-4baf-ad27-07b3f1387393",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ObdMXuCIlLXR",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39a1a2c2-572c-4fc4-8ba9-d4c6ad017cbc",
      "metadata": {
        "tags": [],
        "id": "39a1a2c2-572c-4fc4-8ba9-d4c6ad017cbc"
      },
      "source": [
        "### Funciones globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b5dd6092-f808-4326-af60-1b750a5710fa",
      "metadata": {
        "tags": [],
        "id": "b5dd6092-f808-4326-af60-1b750a5710fa"
      },
      "outputs": [],
      "source": [
        "def calc_once(varname, fn, args):\n",
        "    \"\"\" Calculate a variable only once. \"\"\"\n",
        "    if varname not in globals():\n",
        "        return fn(**args)\n",
        "    return eval(varname)\n",
        "\n",
        "\n",
        "def estimation_model(\n",
        "    layers_props_lst: list, loss_fn: ker.losses.Loss, input_dim: int\n",
        ") -> ker.models.Sequential:\n",
        "    \"\"\" Compile a sequential model for regression purposes. \"\"\"\n",
        "    model = ker.Sequential()\n",
        "    # Hidden layers\n",
        "    for i, layer_props in enumerate(layers_props_lst):\n",
        "        if i == 0:\n",
        "            model.add(ker.layers.Dense(input_dim=input_dim, **layer_props))\n",
        "        else:\n",
        "            model.add(ker.layers.Dense(**layer_props))\n",
        "    # Regressor\n",
        "    model.add(ker.layers.Dense(units=1, activation=\"linear\"))\n",
        "\n",
        "    model.compile(loss=loss_fn, optimizer=\"adam\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def estimation_crossvalidation(X, y, X_prod, y_prod, n_splits, layer_props, loss_fn, callbacks):\n",
        "    \"\"\" Crossvalidation of an estimation network. \"\"\"\n",
        "    # Scores dict\n",
        "    scores = {}\n",
        "    scores[\"model\"] = []\n",
        "    scores[\"loss\"] = []\n",
        "    scores[\"mae\"] = {\"train\": [], \"test\": [], \"prod\": []}\n",
        "    scores[\"r2\"] = {\"train\": [], \"test\": [], \"prod\": []}\n",
        "    scores[\"rmse\"] = {\"train\": [], \"test\": [], \"prod\": []}\n",
        "\n",
        "    # K-fold crossvalidation\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
        "\n",
        "    for train_index, test_index in kf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Input variables standarizer\n",
        "        sc = StandardScaler()\n",
        "        X_train = sc.fit_transform(X_train)\n",
        "        X_test_kf = sc.transform(X_test)\n",
        "        X_prod_kf = sc.transform(X_prod)\n",
        "\n",
        "        model = estimation_model(layer_props, loss_fn, X_train.shape[1])\n",
        "\n",
        "        # Save test scalar loss\n",
        "        if callbacks:\n",
        "            loss = model.fit(\n",
        "                X_train, y_train, epochs=5000, batch_size=64, callbacks=callbacks, verbose=0\n",
        "            )\n",
        "        else:\n",
        "            loss = model.fit(X_train, y_train, epochs=5000, batch_size=64, verbose=0)\n",
        "        print(f\"Needed iterations: {len(loss.history['loss'])}\")\n",
        "        loss = loss.history[\"loss\"]\n",
        "\n",
        "        # Predict using train values\n",
        "        predictions_train = model.predict(X_train, verbose=0).flatten()\n",
        "        # Predict using test values\n",
        "        predictions_test = model.predict(X_test_kf, verbose=0).flatten()\n",
        "        # Predict using production values\n",
        "        predictions_prod = model.predict(X_prod_kf, verbose=0).flatten()\n",
        "\n",
        "        # Dataframe for better visualization\n",
        "        train_data_train = pl.DataFrame(\n",
        "            {\"ICI\": y_train, \"Predicted ICI\": predictions_train}\n",
        "        )\n",
        "        train_data_test = pl.DataFrame(\n",
        "            {\"ICI\": y_test, \"Predicted ICI\": predictions_test}\n",
        "        )\n",
        "        train_data_prod = pl.DataFrame(\n",
        "            {\"ICI\": y_prod, \"Predicted ICI\": predictions_prod}\n",
        "        )\n",
        "\n",
        "        # MAE\n",
        "        mae_score_train = mean_absolute_error(\n",
        "            train_data_train[\"ICI\"], train_data_train[\"Predicted ICI\"]\n",
        "        )\n",
        "        mae_score_test = mean_absolute_error(\n",
        "            train_data_test[\"ICI\"], train_data_test[\"Predicted ICI\"]\n",
        "        )\n",
        "        mae_score_prod = mean_absolute_error(\n",
        "            train_data_prod[\"ICI\"], train_data_prod[\"Predicted ICI\"]\n",
        "        )\n",
        "\n",
        "        # R²\n",
        "        r2_score_train = r2_score(\n",
        "            train_data_train[\"ICI\"], train_data_train[\"Predicted ICI\"]\n",
        "        )\n",
        "        r2_score_test = r2_score(\n",
        "            train_data_test[\"ICI\"], train_data_test[\"Predicted ICI\"]\n",
        "        )\n",
        "        r2_score_prod = r2_score(\n",
        "            train_data_prod[\"ICI\"], train_data_prod[\"Predicted ICI\"]\n",
        "        )\n",
        "\n",
        "        # RMSE\n",
        "        rmse_score_train = mean_squared_error(\n",
        "            train_data_train[\"ICI\"], train_data_train[\"Predicted ICI\"],\n",
        "            squared=False\n",
        "        )\n",
        "        rmse_score_test = mean_squared_error(\n",
        "            train_data_test[\"ICI\"], train_data_test[\"Predicted ICI\"],\n",
        "            squared=False\n",
        "        )\n",
        "        rmse_score_prod = mean_squared_error(\n",
        "            train_data_prod[\"ICI\"], train_data_prod[\"Predicted ICI\"],\n",
        "            squared=False\n",
        "        )\n",
        "\n",
        "        # Append to lists\n",
        "        scores[\"model\"].append(model)\n",
        "        scores[\"loss\"].append(loss)\n",
        "        scores[\"mae\"][\"train\"].append(mae_score_train)\n",
        "        scores[\"mae\"][\"test\"].append(mae_score_test)\n",
        "        scores[\"mae\"][\"prod\"].append(mae_score_prod)\n",
        "        scores[\"r2\"][\"train\"].append(r2_score_train)\n",
        "        scores[\"r2\"][\"test\"].append(r2_score_test)\n",
        "        scores[\"r2\"][\"prod\"].append(r2_score_prod)\n",
        "        scores[\"rmse\"][\"train\"].append(rmse_score_train)\n",
        "        scores[\"rmse\"][\"test\"].append(rmse_score_test)\n",
        "        scores[\"rmse\"][\"prod\"].append(rmse_score_prod)\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "def test_estimation_model(data, data_prod, n_splits, max_neurons, activations,\n",
        "                          use_osnr=True, loss_fn=\"mean_absolute_error\"):\n",
        "    \"\"\" Test a spectral spacing estimation model with given parameters. \"\"\"\n",
        "    n_feat = data.shape[1]\n",
        "    var_n = n_feat - 1 if use_osnr else n_feat - 2\n",
        "\n",
        "    # Split variables\n",
        "    # Variables\n",
        "    X = np.array(data[:, 0:var_n])\n",
        "    X_prod = np.array(data_prod[:, 0:var_n])\n",
        "    # Tags\n",
        "    y = np.array(data[:, -1])\n",
        "    y_prod = np.array(data_prod[:, -1])\n",
        "\n",
        "    # Layer properties\n",
        "    layer_props = [\n",
        "        {\"units\": max_neurons // (2**i), \"activation\": activation}\n",
        "        for i, activation in enumerate(activations)\n",
        "    ]\n",
        "    print(f\"{layer_props}{' + OSNR' if use_osnr else ''}\")\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor=\"loss\", patience=30, mode=\"min\", restore_best_weights=True)\n",
        "    ]\n",
        "\n",
        "    return estimation_crossvalidation(X, y, X_prod, y_prod, n_splits, layer_props, loss_fn, callbacks)\n",
        "\n",
        "def plot_results(x_values, scores, xlabel, log):\n",
        "    plt.figure(figsize=(8, 6), layout=\"constrained\")\n",
        "    plt.scatter(x_values, scores)\n",
        "    plt.plot(x_values, scores)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(\"MAE\")\n",
        "    if log:\n",
        "        plt.xscale(\"log\", base=2)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4efce4fa-5de8-4a54-8685-491ecc648041",
      "metadata": {
        "tags": [],
        "id": "4efce4fa-5de8-4a54-8685-491ecc648041"
      },
      "source": [
        "### Leer CV y separarlos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "75d361a4-bc88-451a-9945-c05e8b3a17ab",
      "metadata": {
        "tags": [],
        "id": "75d361a4-bc88-451a-9945-c05e8b3a17ab",
        "outputId": "e1b119af-13a4-4010-93fd-018f4daf0944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-aedbc0bccfef>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcv16f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv16f_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcv16g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv16g_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(source, has_header, columns, new_columns, separator, comment_char, quote_char, skip_rows, dtypes, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_count_name, row_count_offset, sample_size, eol_char)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pyarrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     ) as data:\n\u001b[0;32m--> 355\u001b[0;31m         df = pli.DataFrame._read_csv(\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mhas_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/polars/dataframe/frame.py\u001b[0m in \u001b[0;36m_read_csv\u001b[0;34m(cls, source, has_header, columns, separator, comment_char, quote_char, skip_rows, dtypes, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_count_name, row_count_offset, sample_size, eol_char)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_projection_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         self._df = PyDataFrame.read_csv(\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0minfer_schema_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: counting_vectors_16f.csv"
          ]
        }
      ],
      "source": [
        "if GOOGLE_COLAB:\n",
        "    cv16f_file = \"counting_vectors_16f.csv\"\n",
        "    cv16g_file = \"counting_vectors_16f.csv\"\n",
        "else:\n",
        "    cv16f_file = \"../../Databases/16GBd/counting_vectors_16f.csv\"\n",
        "    cv16g_file = \"../../Databases/16GBd/counting_vectors_16g.csv\"\n",
        "\n",
        "\n",
        "cv16f = pl.read_csv(cv16f_file, has_header=False, dtypes=[pl.Float64])\n",
        "cv16g = pl.read_csv(cv16g_file, has_header=False, dtypes=[pl.Float64])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe3f3c52-2f24-4206-a56a-4887d5f001e9",
      "metadata": {
        "tags": [],
        "id": "fe3f3c52-2f24-4206-a56a-4887d5f001e9"
      },
      "source": [
        "## FCM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aa7a9ce-69e1-40d3-9833-9e26e649fa00",
      "metadata": {
        "id": "8aa7a9ce-69e1-40d3-9833-9e26e649fa00"
      },
      "outputs": [],
      "source": [
        "# Show the original dataframe\n",
        "cv16f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f300c3-eb56-4e90-bad2-4fd476f30b31",
      "metadata": {
        "id": "f4f300c3-eb56-4e90-bad2-4fd476f30b31"
      },
      "outputs": [],
      "source": [
        "# Shuffle the dataframe\n",
        "cv16f_shuffled = cv16f.sample(n=len(cv16f), shuffle=True, seed=1036681523)\n",
        "print(cv16f_shuffled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e079b32-d271-4ca7-85e1-64c72c09c89a",
      "metadata": {
        "id": "5e079b32-d271-4ca7-85e1-64c72c09c89a"
      },
      "outputs": [],
      "source": [
        "# Extract 10% of the data to use later for \"production\" testing\n",
        "cv16f_prod = cv16f_shuffled[:int(len(cv16f_shuffled)*0.1)]\n",
        "print(cv16f_prod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5bc5587-8508-4809-a9eb-10a4cb51eb03",
      "metadata": {
        "id": "e5bc5587-8508-4809-a9eb-10a4cb51eb03"
      },
      "outputs": [],
      "source": [
        "# Use the rest of the data for normal testing\n",
        "cv16f_new = cv16f_shuffled[int(len(cv16f_shuffled)*0.1):]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7171c0b-812c-4e54-b46b-91480904a9a4",
      "metadata": {
        "id": "c7171c0b-812c-4e54-b46b-91480904a9a4"
      },
      "source": [
        "### Evaluación de hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fffca2c3-15d4-4d50-bbe3-44fa538e51cb",
      "metadata": {
        "id": "fffca2c3-15d4-4d50-bbe3-44fa538e51cb"
      },
      "source": [
        "Se evaluará una combinación de parámetros:\n",
        "- Número de neuronas máximas por capa (8, 16, 32, 64, 128, 256, 512, 1024).\n",
        "- Número de capas (1, 2, 3).\n",
        "- Combinación de funciones de activación (ReLu, tanh, sigmoid).\n",
        "- El usar o no la OSNR como característica adicional.\n",
        "\n",
        "Los resultados tendrán la siguiente estructura:\n",
        "```\n",
        "{\"xyz\": {\"n_neurons\": {\"osnr/wo_osnr\": results}}}\n",
        "```\n",
        "Donde xyz serán las iniciales de las combinaciones de funciones de activación, n_neurons será el número de neuronas máximo, osnr/wo_osnr será la indicación de si se usó o no el OSNR como característica y results será el objeto resultante que contiene todos los resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27927d24-4ad8-4a25-b63d-dd5e54dfc0b0",
      "metadata": {
        "tags": [],
        "id": "27927d24-4ad8-4a25-b63d-dd5e54dfc0b0"
      },
      "outputs": [],
      "source": [
        "osnr_lst = [\"osnr\", \"wo_osnr\"]\n",
        "max_neurons = [str(2**n) for n in range(3, 11)]\n",
        "functs = [\"relu\", \"tanh\", \"sigmoid\"]\n",
        "layers_n = [1, 2, 3]\n",
        "\n",
        "combinations = [\n",
        "    [list(subset) for subset in product(functs, repeat=n)]\n",
        "    for n in layers_n\n",
        "]\n",
        "\n",
        "hidden_layers = [item for sublist in combinations for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c29e306-cde9-4113-924a-ec3bd07e0d71",
      "metadata": {
        "id": "1c29e306-cde9-4113-924a-ec3bd07e0d71"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    cv16f_reg_results = sofa.load_hdf5(f\"{ROOT}/cv16f_reg_results.h5\")\n",
        "except:\n",
        "    print(\"Error loading from file, creating a new dictionary\")\n",
        "    cv16f_reg_results = defaultdict(defaultdict(defaultdict(defaultdict().copy).copy).copy)\n",
        "\n",
        "# Evaluar\n",
        "for activations in hidden_layers:\n",
        "    for neurons in max_neurons:\n",
        "        for osnr in osnr_lst:\n",
        "            args = {\"data\": cv16f_new, \"data_prod\": cv16f_prod, \"n_splits\": 5, \"max_neurons\": int(neurons), \"activations\": activations, \"use_osnr\": True if osnr == \"osnr\" else False}\n",
        "            act_fn_name = \"\".join([s[0] for s in activations])\n",
        "            if cv16f_reg_results[act_fn_name][neurons][osnr] == defaultdict():\n",
        "                # Get results\n",
        "                results = test_estimation_model(**args)\n",
        "                # Serialize model\n",
        "                results[\"model\"] = [utils.serialize_keras_object(model) for model in results[\"model\"]]\n",
        "                # Save serialized model for serialization\n",
        "                cv16f_reg_results[act_fn_name][neurons][osnr] = results\n",
        "                # Save results with serialized model\n",
        "                print(\"Saving results...\")\n",
        "                sofa.save_hdf5(cv16f_reg_results, f\"{ROOT}/cv16f_reg_results.h5\")\n",
        "                print(\"Results saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91445933-554a-4ff9-a694-8352380b19ae",
      "metadata": {
        "id": "91445933-554a-4ff9-a694-8352380b19ae"
      },
      "source": [
        "### Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f757c6-1f28-4730-87e5-56683d000b44",
      "metadata": {
        "tags": [],
        "id": "83f757c6-1f28-4730-87e5-56683d000b44"
      },
      "outputs": [],
      "source": [
        "def get_avg_score(results, target_value, target=\"neurons\", metric=\"mae\", score=\"test\"):\n",
        "    mae_lst = []\n",
        "    for activations in hidden_layers:\n",
        "        if target == \"layers\" and len(activations) != target_value:\n",
        "            continue\n",
        "        for neurons in max_neurons:\n",
        "            if target == \"neurons\" and neurons != target_value:\n",
        "                continue\n",
        "            for osnr in osnr_lst:\n",
        "                if target == \"osnr\" and osnr != target_value:\n",
        "                    continue\n",
        "                act_fn_name = \"\".join([s[0] for s in activations])\n",
        "                mae_lst.append(np.mean(results[act_fn_name][neurons][osnr][\"mae\"][\"test\"]))\n",
        "    return mae_lst\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neurons_avg_results = [np.mean(get_avg_score(cv16f_reg_results, neurons, target=\"neurons\", metric=\"mae\", score=\"test\")) for neurons in max_neurons]\n",
        "x = list(map(int, max_neurons))\n",
        "plot_results(x, neurons_avg_results, \"Maximum number of neurons\", log=True)"
      ],
      "metadata": {
        "id": "DFDTFw5QUftS"
      },
      "id": "DFDTFw5QUftS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08af0301-f030-4210-88aa-a29f2c6bfba3",
      "metadata": {
        "tags": [],
        "id": "08af0301-f030-4210-88aa-a29f2c6bfba3"
      },
      "outputs": [],
      "source": [
        "layers_avg_results = [np.mean(get_avg_score(cv16f_reg_results, layers, target=\"layers\", metric=\"mae\", score=\"test\")) for layers in range(1, 4)]\n",
        "x = range(1, 4)\n",
        "plot_results(x, layers_avg_results, \"Number of layers\", log=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504675ce-fd55-49d0-95fd-dcff312cbaeb",
      "metadata": {
        "tags": [],
        "id": "504675ce-fd55-49d0-95fd-dcff312cbaeb"
      },
      "outputs": [],
      "source": [
        "osnr_avg_results = [np.mean(get_avg_score(cv16f_reg_results, osnr, target=\"osnr\", metric=\"mae\", score=\"test\")) for osnr in [\"osnr\", \"wo_osnr\"]]\n",
        "print(f\"Con OSNR  Sin OSNR\")\n",
        "print(f\"{osnr_avg_results[0]:.3f}       {osnr_avg_results[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d7534de-2700-4ed5-a213-60a105904ac5",
      "metadata": {
        "id": "9d7534de-2700-4ed5-a213-60a105904ac5"
      },
      "source": [
        "### Ordenar modelos por puntaje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bed53e1-b29f-4dfc-8df7-ca9c7c6913e4",
      "metadata": {
        "id": "8bed53e1-b29f-4dfc-8df7-ca9c7c6913e4"
      },
      "outputs": [],
      "source": [
        "# Find better model by test score\n",
        "def get_better_models(results, metric=\"mae\", score=\"test\"):\n",
        "    scores = []\n",
        "    for activations in hidden_layers:\n",
        "        for neurons in max_neurons:\n",
        "            for osnr in osnr_lst:\n",
        "                act_fn_name = \"\".join([s[0] for s in activations])\n",
        "                coll = cv16f_reg_results[act_fn_name][neurons][osnr][metric][score]\n",
        "                if isinstance(coll, defaultdict):\n",
        "                    continue\n",
        "                score_value = np.mean(coll)\n",
        "                scores.append((score_value, [act_fn_name, neurons, osnr]))\n",
        "    scores.sort(key=lambda x: x[0])\n",
        "    return pl.dataframe.DataFrame(scores)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "better_models_df = get_better_models(cv16f_reg_results, metric=\"mae\", score=\"test\")\n",
        "better_models_df.head(25)"
      ],
      "metadata": {
        "id": "PT2mJucuX-Rf"
      },
      "id": "PT2mJucuX-Rf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJtVt2GMX_uk"
      },
      "id": "cJtVt2GMX_uk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "QnkjCjBmpPZI"
      },
      "source": [
        "## GKM"
      ],
      "id": "QnkjCjBmpPZI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O10egjkUpPZP"
      },
      "outputs": [],
      "source": [
        "# Show the original dataframe\n",
        "cv16g"
      ],
      "id": "O10egjkUpPZP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Klpuu9ojpPZP"
      },
      "outputs": [],
      "source": [
        "# Shuffle the dataframe\n",
        "cv16g_shuffled = cv16g.sample(n=len(cv16g), shuffle=True, seed=1036681523)\n",
        "print(cv16g_shuffled)"
      ],
      "id": "Klpuu9ojpPZP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5hfSk7apPZQ"
      },
      "outputs": [],
      "source": [
        "# Extract 10% of the data to use later for \"production\" testing\n",
        "cv16g_prod = cv16g_shuffled[:int(len(cv16g_shuffled)*0.1)]\n",
        "print(cv16g_prod)"
      ],
      "id": "-5hfSk7apPZQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLYS1pSOpPZQ"
      },
      "outputs": [],
      "source": [
        "# Use the rest of the data for normal testing\n",
        "cv16g_new = cv16g_shuffled[int(len(cv16g_shuffled)*0.1):]"
      ],
      "id": "FLYS1pSOpPZQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP8pzAJspPZQ"
      },
      "source": [
        "### Evaluación de hiperparámetros"
      ],
      "id": "lP8pzAJspPZQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kerkIfwQpPZR"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    cv16g_reg_results = sofa.load_hdf5(f\"{ROOT}/cv16g_reg_results.h5\")\n",
        "except:\n",
        "    print(\"Error loading from file, creating a new dictionary\")\n",
        "    cv16g_reg_results = defaultdict(defaultdict(defaultdict(defaultdict().copy).copy).copy)\n",
        "\n",
        "# Evaluar\n",
        "for activations in hidden_layers:\n",
        "    for neurons in max_neurons:\n",
        "        for osnr in osnr_lst:\n",
        "            args = {\"data\": cv16g_new, \"data_prod\": cv16g_prod, \"n_splits\": 5, \"max_neurons\": int(neurons), \"activations\": activations, \"use_osnr\": True if osnr == \"osnr\" else False}\n",
        "            act_fn_name = \"\".join([s[0] for s in activations])\n",
        "            if cv16g_reg_results[act_fn_name][neurons][osnr] == defaultdict():\n",
        "                # Get results\n",
        "                results = test_estimation_model(**args)\n",
        "                # Serialize model\n",
        "                results[\"model\"] = [utils.serialize_keras_object(model) for model in results[\"model\"]]\n",
        "                # Save serialized model for serialization\n",
        "                cv16g_reg_results[act_fn_name][neurons][osnr] = results\n",
        "                # Save results with serialized model\n",
        "                print(\"Saving results...\")\n",
        "                sofa.save_hdf5(cv16g_reg_results, f\"{ROOT}/cv16g_reg_results.h5\")\n",
        "                print(\"Results saved!\")"
      ],
      "id": "kerkIfwQpPZR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wajZsRKpPZR"
      },
      "source": [
        "### Resultados"
      ],
      "id": "1wajZsRKpPZR"
    },
    {
      "cell_type": "code",
      "source": [
        "neurons_avg_results = [np.mean(get_avg_score(cv16g_reg_results, neurons, target=\"neurons\", metric=\"mae\", score=\"test\")) for neurons in max_neurons]\n",
        "x = list(map(int, max_neurons))\n",
        "plot_results(x, neurons_avg_results, \"Maximum number of neurons\", log=True)"
      ],
      "metadata": {
        "id": "XxiXylIEpPZR"
      },
      "execution_count": null,
      "outputs": [],
      "id": "XxiXylIEpPZR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "5VYw1iNMpPZR"
      },
      "outputs": [],
      "source": [
        "layers_avg_results = [np.mean(get_avg_score(cv16g_reg_results, layers, target=\"layers\", metric=\"mae\", score=\"test\")) for layers in range(1, 4)]\n",
        "x = range(1, 4)\n",
        "plot_results(x, layers_avg_results, \"Number of layers\", log=False)"
      ],
      "id": "5VYw1iNMpPZR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "8j0gDA9YpPZR"
      },
      "outputs": [],
      "source": [
        "osnr_avg_results = [np.mean(get_avg_score(cv16g_reg_results, osnr, target=\"osnr\", metric=\"mae\", score=\"test\")) for osnr in [\"osnr\", \"wo_osnr\"]]\n",
        "print(f\"Con OSNR  Sin OSNR\")\n",
        "print(f\"{osnr_avg_results[0]:.3f}       {osnr_avg_results[1]:.3f}\")"
      ],
      "id": "8j0gDA9YpPZR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3cJ9Go3pPZR"
      },
      "source": [
        "### Ordenar modelos por puntaje"
      ],
      "id": "H3cJ9Go3pPZR"
    },
    {
      "cell_type": "code",
      "source": [
        "better_models_df = get_better_models(cv16g_reg_results, metric=\"mae\", score=\"test\")\n",
        "better_models_df.head(25)"
      ],
      "metadata": {
        "id": "ItMtirWupPZS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ItMtirWupPZS"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EuUhyFvVpPZS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "EuUhyFvVpPZS"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}