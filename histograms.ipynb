{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59be66b6-f376-484e-8c2b-c5d58a38c942",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Estimación de ICI mediante histogramas de diagramas de constelación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914a3e1-f282-4380-ac57-5d2be93c2e0b",
   "metadata": {},
   "source": [
    "## Tareas\n",
    "- [X] Hacerlo 2D\n",
    "- [ ] Con ambos utilizar un clasificador\n",
    "- [ ] En caso tal, variar los bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408abaa0-933f-499a-accc-5fe826ffcd58",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c7e5b55a-87f0-47ea-9a51-942c2216202b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sofa\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as ker\n",
    "import json\n",
    "import os\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import multivariate_normal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import (accuracy_score, f1_score, multilabel_confusion_matrix,\n",
    "                             ConfusionMatrixDisplay)\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras import models, regularizers, Sequential, utils\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from itertools import product\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1a2c2-572c-4fc4-8ba9-d4c6ad017cbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Funciones globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b02dcfd1-b001-4072-9f6c-02ac61f5fe10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función especial para leer todos los datos con la estructura estudiada\n",
    "def read_data(folder_rx):\n",
    "    data = {}\n",
    "\n",
    "    # Leer la carpeta principal\n",
    "    for folder in os.listdir(folder_rx):\n",
    "        # Leer las subcarpetas\n",
    "        if folder.endswith(\"spacing\"):\n",
    "            data[folder] = {}\n",
    "            for file in os.listdir(f\"{folder_rx}/{folder}\"):\n",
    "                if file.find(\"consY\") != -1:\n",
    "                    data_name = file.split(\"_\")[2]\n",
    "                    if data[folder].get(data_name) == None:\n",
    "                        data[folder][data_name] = {}\n",
    "                    mat_file_data = loadmat(f\"{folder_rx}/{folder}/{file}\")\n",
    "                    data[folder][data_name] = mat_file_data\n",
    "    return data\n",
    "\n",
    "def plot_constellation_diagram(X, ax):\n",
    "    ax.scatter(X.real, X.imag, alpha=0.5)\n",
    "    ax.set_title(\"Constellation diagram\")\n",
    "    ax.set_xlabel(\"I\")\n",
    "    ax.set_ylabel(\"Q\")\n",
    "    \n",
    "def calculate_gmm(data, gm_kwargs):\n",
    "    return GaussianMixture(**gm_kwargs).fit(data)\n",
    "    \n",
    "def calculate_1d_histogram(X, bins):\n",
    "    hist_y, hist_x = np.histogram(X.real, bins=bins)\n",
    "    # Remove last bin edge\n",
    "    hist_x = hist_x[:-1]\n",
    "    \n",
    "    return hist_x, hist_y\n",
    "\n",
    "def plot_1d_histogram(X, ax):\n",
    "    ax.hist(X, bins=bins, density=True, alpha=0.5, label=\"Calculated histogram\")\n",
    "    \n",
    "def plot_gmm_1d(gm, limits):\n",
    "    x = np.linspace(*limits, 1000)\n",
    "    \n",
    "    logprob = gm.score_samples(x.reshape(-1, 1))\n",
    "    responsibilities = gm.predict_proba(x.reshape(-1, 1))\n",
    "    pdf = np.exp(logprob)\n",
    "    pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "    \n",
    "    ax.plot(x, pdf_individual, '--', label=\"Adjusted histogram\")\n",
    "\n",
    "def plot_gmm_2d(gm, limits, ax):\n",
    "    x = y = np.linspace(*limits)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = -gm.score_samples(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)\n",
    "\n",
    "    ax.contour(\n",
    "        X, Y, Z,\n",
    "        norm=LogNorm(vmin=1.0, vmax=1000.0), \n",
    "        levels=np.logspace(0, 3, 25), cmap=\"seismic\"\n",
    "    )\n",
    "    \n",
    "def calculate_3d_histogram(X, bins, limits, spacing, snr):\n",
    "    hist, xedges, yedges = np.histogram2d(X.real, X.imag, bins=bins, range=[[*limits], [*limits]])\n",
    "\n",
    "    # Define the extent\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "    # Create the meshgrid for the surface plot, excluding the last edge\n",
    "    x_mesh, y_mesh = np.meshgrid(xedges[:-1], yedges[:-1])\n",
    "    \n",
    "    return hist, x_mesh, y_mesh\n",
    "    \n",
    "def plot_3d_histogram(x_mesh, y_mesh, hist, ax):\n",
    "    ax.plot_surface(x_mesh, y_mesh, hist.T, cmap=\"seismic\", rstride=1, cstride=1, edgecolor=\"none\")\n",
    "    ax.set_title(\"3D Histogram\")\n",
    "    ax.set_xlabel(\"I\")\n",
    "    ax.set_ylabel(\"Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b5dd6092-f808-4326-af60-1b750a5710fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_once(varname, fn, args):\n",
    "    \"\"\" Calculate a variable only once. \"\"\"\n",
    "    if varname not in globals():\n",
    "        return fn(**args)\n",
    "    return eval(varname)\n",
    "\n",
    "def classificator(df, interval_lst, column_name):\n",
    "    \"\"\"Transforms a dataframe's column into classes\"\"\"\n",
    "    array = df[column_name].to_numpy()\n",
    "    indexes_lst = []\n",
    "    for i, interval in enumerate(interval_lst):\n",
    "        lower_limit, upper_limit = interval\n",
    "        indexes_lst.append(np.intersect1d(np.where(lower_limit < array), np.where(array <= upper_limit)))\n",
    "    \n",
    "    classfull = df[column_name]\n",
    "    for index, indexes in enumerate(indexes_lst):\n",
    "        classfull[indexes] = index\n",
    "\n",
    "    df_classfull = df.clone()\n",
    "    df_classfull.replace(column_name, classfull)\n",
    "    \n",
    "    return df_classfull\n",
    "\n",
    "def classifier_model(input_dim, layers_props_lst, classes_n, loss_fn):\n",
    "    \"\"\" Compile a sequential model for classification purposes. \"\"\"\n",
    "    model = ker.Sequential()\n",
    "    # Hidden layers\n",
    "    for i, layer_props in enumerate(layers_props_lst):\n",
    "        if i == 0:\n",
    "            model.add(ker.layers.Dense(**layer_props, input_dim=input_dim))\n",
    "        else:\n",
    "            model.add(ker.layers.Dense(**layer_props))\n",
    "    # Classifier\n",
    "    model.add(ker.layers.Dense(units=classes_n, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=loss_fn, optimizer=\"adam\")\n",
    "    return model    \n",
    "\n",
    "\n",
    "def classification_crossvalidation(X, y, n_splits, layer_props, classes_n, loss_fn, callbacks):\n",
    "    \"\"\" Crossvalidation of a classification network. \"\"\"\n",
    "    # Store initial time\n",
    "    t0 = time()\n",
    "\n",
    "    # Scores dict\n",
    "    scores = {}\n",
    "    scores[\"loss\"] = []\n",
    "    scores[\"acc\"] = {\"train\": [], \"test\": []}\n",
    "    scores[\"f1\"] = {\"train\": [], \"test\": []}\n",
    "    scores[\"cm\"] = {\"train\": [], \"test\": []}\n",
    "    \n",
    "    # K-fold crossvalidation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Input variables standarizer\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test_kf = sc.transform(X_test)\n",
    "        \n",
    "        model = classifier_model(X_train.shape[1], layer_props, classes_n, loss_fn)\n",
    "        \n",
    "        # Save test scalar loss\n",
    "        if callbacks:\n",
    "            loss = model.fit(\n",
    "                X_train, y_train, epochs=5000, batch_size=64, verbose=0, callbacks=callbacks\n",
    "            )\n",
    "        else:\n",
    "            loss = model.fit(X_train, y_train, epochs=5000, batch_size=64, verbose=0)\n",
    "        print(f\"Needed iterations: {len(loss.history['loss'])}\")\n",
    "        \n",
    "        # Predict using train values\n",
    "        fuzzy_predictions_train = model.predict(X_train)\n",
    "        # Predict using test values\n",
    "        fuzzy_predictions_test = model.predict(X_test_kf)\n",
    "        \n",
    "        # Assign class based on higher probability in membership vector\n",
    "        predictions_train = np.array([np.argmax(fuzzy_prediction) for fuzzy_prediction in fuzzy_predictions_train])\n",
    "        predictions_test = np.array([np.argmax(fuzzy_prediction) for fuzzy_prediction in fuzzy_predictions_test])\n",
    "\n",
    "        # Dataframe for better visualization\n",
    "        train_data_train = pl.DataFrame(\n",
    "            {\"ICI\": [y_train], \"Predicted ICI\": [predictions_train]}\n",
    "        )\n",
    "        train_data_test = pl.DataFrame(\n",
    "            {\"ICI\": [y_test], \"Predicted ICI\": [predictions_test]}\n",
    "        )\n",
    "\n",
    "        # Accuracy\n",
    "        acc_score_train = accuracy_score(\n",
    "            *train_data_train[\"ICI\"], *train_data_train[\"Predicted ICI\"]\n",
    "        )\n",
    "        acc_score_test = accuracy_score(\n",
    "            *train_data_test[\"ICI\"], *train_data_test[\"Predicted ICI\"]\n",
    "        )\n",
    "\n",
    "        # F1\n",
    "        f1_score_train = f1_score(\n",
    "            *train_data_train[\"ICI\"], *train_data_train[\"Predicted ICI\"],\n",
    "            average=\"micro\"\n",
    "        )\n",
    "        f1_score_test = f1_score(\n",
    "            *train_data_test[\"ICI\"], *train_data_test[\"Predicted ICI\"],\n",
    "            average=\"micro\"\n",
    "        )\n",
    "         \n",
    "        # Confusion Matrix\n",
    "        cm_score_train = multilabel_confusion_matrix(\n",
    "            *train_data_train[\"ICI\"], *train_data_train[\"Predicted ICI\"]\n",
    "        )\n",
    "        cm_score_test = multilabel_confusion_matrix(\n",
    "            *train_data_test[\"ICI\"], *train_data_test[\"Predicted ICI\"]\n",
    "        )\n",
    "\n",
    "        # Append to lists\n",
    "        scores[\"loss\"].append(loss)\n",
    "        scores[\"acc\"][\"train\"].append(acc_score_train)\n",
    "        scores[\"acc\"][\"test\"].append(acc_score_test)\n",
    "        scores[\"f1\"][\"train\"].append(f1_score_train)\n",
    "        scores[\"f1\"][\"test\"].append(f1_score_test)\n",
    "        scores[\"cm\"][\"train\"].append(cm_score_train)\n",
    "        scores[\"cm\"][\"test\"].append(cm_score_test)\n",
    "        \n",
    "    print(f\"Time elapsed: {(time() - t0)/60:.2f} minutes\")\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def test_classification_model(data, n_splits, max_neurons, activations, classes_n,\n",
    "                               use_osnr=True, loss_fn=\"sparse_categorical_crossentropy\"):\n",
    "    \"\"\" Test a spectral overlapping classification model with given parameters. \"\"\"\n",
    "    # Set variable number\n",
    "    var_n = 17 if use_osnr else 16\n",
    "    \n",
    "    # Split variables\n",
    "    # Variables\n",
    "    X = np.array(data[:, 0:var_n]).T\n",
    "    # Tags\n",
    "    y = np.array(data[:, 19:20]).T\n",
    "    \n",
    "    # Layer properties\n",
    "    layer_props = [\n",
    "        {\"units\": max_neurons // (2**i), \"activation\": activation}\n",
    "        for i, activation in enumerate(activations)\n",
    "    ]\n",
    "    print(layer_props)\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"loss\", patience=30, mode=\"min\", restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    return classification_crossvalidation(X, y, n_splits, layer_props, classes_n, loss_fn, callbacks)\n",
    "\n",
    "def plot_classes_scores(scores, scenario):\n",
    "    score_names = [\"acc\"]\n",
    "    data_type = [\"train\", \"test\"]\n",
    "    markers = [\"o\", \"D\", \"o\", \"D\"]\n",
    "    colors = [\"dodgerblue\", \"dodgerblue\", \"red\", \"red\"]\n",
    "    \n",
    "    # Plot loss\n",
    "    plot_losses(scores, scenario, \n",
    "                lambda index: f\"{'FCM' if index%2==0 else 'GKM'} {'B2B' if index<2 else 'optical fiber at ' + ('0' if index<4 else '9') + ' dBm'}\",\n",
    "                based_on_index=True)\n",
    "    \n",
    "    # Plot scores\n",
    "    plot_scores(scores, [\"B2B\", \"0 dBm\", \"9 dBm\"], scenario, score_names,\n",
    "                data_type, label=lambda index: f\"{'FCM' if index%2==0 else 'GKM'}\",\n",
    "                xlabel=\"Scenario\", markers=markers, colors=colors, multiple_points=True,\n",
    "                based_on_index=True)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_cm(scores, interval_lst):\n",
    "    CM = np.array(scores.get(\"cm\").get(\"test\"))\n",
    "    for n, interval in enumerate(interval_lst):\n",
    "        result = np.zeros(CM[0][0].shape)\n",
    "        for cm in CM:\n",
    "            result = np.add(result, cm[n])\n",
    "        result /= np.sum(result)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=result, display_labels=[\"Positive\", \"Negative\"])\n",
    "        disp.plot(colorbar=False)\n",
    "        lower_limit, upper_limit = interval \n",
    "        plt.title(f\"Confusion matrix for class from {lower_limit} GHz up to {upper_limit} GHz\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efce4fa-5de8-4a54-8685-491ecc648041",
   "metadata": {},
   "source": [
    "## Leer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "75d361a4-bc88-451a-9945-c05e8b3a17ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_tx = \"Demodulation/Data/2x16QAM_16GBd.mat\"\n",
    "folder_rx = \"Demodulation/Data/\"\n",
    "\n",
    "# Transmitted data\n",
    "X_tx_norm = loadmat(file_tx)\n",
    "X_tx_norm = X_tx_norm.get(\"Constellation\").flatten()[0][0].flatten()\n",
    "X_tx = sofa.mod_norm(X_tx_norm, 10)*X_tx_norm\n",
    "\n",
    "# Read received data\n",
    "data = read_data(folder_rx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b3c94-9896-4f2d-ac62-4e16a65274c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Obtener histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b0a6a99-4b60-424f-87dc-c482366b25e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = False\n",
    "spacings = [\"15\", \"15.5\", \"16\", \"16.5\", \"17\", \"17.6\", \"18\"]\n",
    "\n",
    "histograms = {}\n",
    "gaussians = {}\n",
    "bins = 128\n",
    "limits = [-5, 5]\n",
    "\n",
    "for spacing in spacings:\n",
    "    X_rx = data[f\"{spacing}GHz_spacing\"]\n",
    "    for snr in X_rx:\n",
    "        # Extract data \n",
    "        X_ch_norm = X_rx[snr].get(\"const_Y\").flatten()\n",
    "        X_ch = sofa.mod_norm(X_ch_norm, 10)*X_ch_norm\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(12, 12), layout=\"tight\")\n",
    "\n",
    "            # Plot constellation diagram\n",
    "            ax = plt.subplot(2, 2, 1)\n",
    "            plot_constellation_diagram(X_ch, ax)\n",
    "        \n",
    "        # Calculate 2D GMM\n",
    "        input_data = np.vstack((X_ch.real, X_ch.imag)).T\n",
    "        gm_kwargs = {\n",
    "            \"means_init\": np.array(list(product([-3, -1, 1, 3], repeat=2))), \n",
    "            \"n_components\": 16\n",
    "        }\n",
    "        gm_2d = calculate_gmm(input_data, gm_kwargs)\n",
    "        \n",
    "        if plot:\n",
    "            # Plot 2D GMM\n",
    "            plot_gmm_2d(gm_2d, limits, ax)\n",
    "            ax.grid(True)\n",
    "\n",
    "        # Calculate 3D histogram\n",
    "        hist, x_mesh, y_mesh = calculate_3d_histogram(X_ch, bins, limits, spacing, snr)\n",
    "        \n",
    "        # Save 3D histogram\n",
    "        if histograms.get(f\"{spacing}GHz_spacing\") == None:\n",
    "            histograms[f\"{spacing}GHz_spacing\"] = {}\n",
    "        histograms[f\"{spacing}GHz_spacing\"][snr[5:]] = hist\n",
    "    \n",
    "        if plot:\n",
    "            # Plot 3D histogram\n",
    "            ax = plt.subplot(2, 2, 2, projection=\"3d\")\n",
    "            plot_3d_histogram(x_mesh, y_mesh, hist, ax)\n",
    "\n",
    "        # Plot I and Q histograms separately\n",
    "        # I\n",
    "        if plot:\n",
    "            ax = plt.subplot(2, 2, 3)\n",
    "            plot_1d_histogram(X_ch.real, ax)\n",
    "        \n",
    "        hist_x, hist_y = calculate_1d_histogram(X_ch.real, bins)\n",
    "        input_data = np.repeat(hist_x, hist_y).reshape(-1, 1)\n",
    "        gm_kwargs = {\n",
    "            \"means_init\": np.array([-3, -1, 1, 3]).reshape(4, 1), \n",
    "            \"n_components\": 4\n",
    "        }\n",
    "        gm_i = calculate_gmm(input_data, gm_kwargs)\n",
    "        if plot:\n",
    "            plot_gmm_1d(gm_i, limits)\n",
    "        \n",
    "            ax.set_title(\"I-Histogram\")\n",
    "            ax.set_xlabel(\"I\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        # Q\n",
    "        if plot:\n",
    "            ax = plt.subplot(2, 2, 4)\n",
    "            plot_1d_histogram(X_ch.imag, ax)\n",
    "        \n",
    "        hist_x, hist_y = calculate_1d_histogram(X_ch.imag, bins)\n",
    "        input_data = np.repeat(hist_x, hist_y).reshape(-1, 1)\n",
    "        gm_kwargs = {\n",
    "            \"means_init\": np.array([-3, -1, 1, 3]).reshape(4, 1), \n",
    "            \"n_components\": 4\n",
    "        }\n",
    "        gm_q = calculate_gmm(input_data, gm_kwargs)\n",
    "        if plot:\n",
    "            plot_gmm_1d(gm_q, limits)\n",
    "            \n",
    "            ax.set_title(\"Q-Histogram\")\n",
    "            ax.set_xlabel(\"Q\")\n",
    "            ax.grid(True)\n",
    "    \n",
    "        # Save gaussians\n",
    "        if gaussians.get(f\"{spacing}GHz_spacing\") == None:\n",
    "            gaussians[f\"{spacing}GHz_spacing\"] = {}\n",
    "        gaussians[f\"{spacing}GHz_spacing\"][snr[5:]] = [gm_2d, gm_i, gm_q]\n",
    "\n",
    "        if plot:\n",
    "            plt.suptitle(f\"Plots for {snr[5:]} OSNR and {spacing} GHz of spacing\")\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dedd46-4b31-44de-a82b-438db4fb61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacings = [\"15\", \"15.5\", \"16\", \"16.5\", \"17\", \"17.6\", \"18\"]\n",
    "\n",
    "for spacing in spacings:\n",
    "    X_rx = data[f\"{spacing}GHz_spacing\"]\n",
    "    for snr in X_rx:\n",
    "        # Extract data \n",
    "        X_ch_norm = X_rx[snr].get(\"const_Y\").flatten()\n",
    "        X_ch = sofa.mod_norm(X_ch_norm, 10)*X_ch_norm\n",
    "\n",
    "        plt.figure(figsize=(12, 12), layout=\"tight\")\n",
    "\n",
    "        # Plot constellation diagram\n",
    "        ax = plt.subplot(2, 2, 1)\n",
    "        plot_constellation_diagram(X_ch, ax)\n",
    "        \n",
    "        gm_2d = gaussians.get(f\"{spacing}GHz_spacing\").get(f\"{snr[5:]}\")[0]\n",
    "        \n",
    "        # Plot 2D GMM\n",
    "        plot_gmm_2d(gm_2d, limits, ax)\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Calculate 3D histogram\n",
    "        hist, x_mesh, y_mesh = calculate_3d_histogram(X_ch, bins, limits, spacing, snr)\n",
    "        \n",
    "        # Save 3D histogram\n",
    "        if histograms.get(f\"{spacing}GHz_spacing\") == None:\n",
    "            histograms[f\"{spacing}GHz_spacing\"] = {}\n",
    "        histograms[f\"{spacing}GHz_spacing\"][snr[5:]] = hist\n",
    "    \n",
    "        if plot:\n",
    "            # Plot 3D histogram\n",
    "            ax = plt.subplot(2, 2, 2, projection=\"3d\")\n",
    "            plot_3d_histogram(x_mesh, y_mesh, hist, ax)\n",
    "\n",
    "        # Plot I and Q histograms separately\n",
    "        # I\n",
    "        if plot:\n",
    "            ax = plt.subplot(2, 2, 3)\n",
    "            plot_1d_histogram(X_ch.real, ax)\n",
    "        \n",
    "        hist_x, hist_y = calculate_1d_histogram(X_ch.real, bins)\n",
    "        input_data = np.repeat(hist_x, hist_y).reshape(-1, 1)\n",
    "        gm_kwargs = {\n",
    "            \"means_init\": np.array([-3, -1, 1, 3]).reshape(4, 1), \n",
    "            \"n_components\": 4\n",
    "        }\n",
    "        gm_i = calculate_gmm(input_data, gm_kwargs)\n",
    "        if plot:\n",
    "            plot_gmm_1d(gm_i, limits)\n",
    "        \n",
    "            ax.set_title(\"I-Histogram\")\n",
    "            ax.set_xlabel(\"I\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        # Q\n",
    "        if plot:\n",
    "            ax = plt.subplot(2, 2, 4)\n",
    "            plot_1d_histogram(X_ch.imag, ax)\n",
    "        \n",
    "        hist_x, hist_y = calculate_1d_histogram(X_ch.imag, bins)\n",
    "        input_data = np.repeat(hist_x, hist_y).reshape(-1, 1)\n",
    "        gm_kwargs = {\n",
    "            \"means_init\": np.array([-3, -1, 1, 3]).reshape(4, 1), \n",
    "            \"n_components\": 4\n",
    "        }\n",
    "        gm_q = calculate_gmm(input_data, gm_kwargs)\n",
    "        if plot:\n",
    "            plot_gmm_1d(gm_q, limits)\n",
    "            \n",
    "            ax.set_title(\"Q-Histogram\")\n",
    "            ax.set_xlabel(\"Q\")\n",
    "            ax.grid(True)\n",
    "    \n",
    "        # Save gaussians\n",
    "        if gaussians.get(f\"{spacing}GHz_spacing\") == None:\n",
    "            gaussians[f\"{spacing}GHz_spacing\"] = {}\n",
    "        gaussians[f\"{spacing}GHz_spacing\"][snr[5:]] = [gm_2d, gm_i, gm_q]\n",
    "\n",
    "        if plot:\n",
    "            plt.suptitle(f\"Plots for {snr[5:]} OSNR and {spacing} GHz of spacing\")\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f3c52-2f24-4206-a56a-4887d5f001e9",
   "metadata": {},
   "source": [
    "## Preparar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cc4ceb73-290b-430c-b5e3-7ed4b544b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (70, 98)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬──────────┬───────┬───────┐\n",
      "│ col0      ┆ col1      ┆ col2      ┆ col3      ┆ … ┆ col94     ┆ col95    ┆ col96 ┆ col97 │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---      ┆ ---   ┆ ---   │\n",
      "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64      ┆ f64   ┆ f64   │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪══════════╪═══════╪═══════╡\n",
      "│ -3.061791 ┆ -3.083884 ┆ -3.011383 ┆ -1.095477 ┆ … ┆ 0.003165  ┆ 0.263649 ┆ 35.0  ┆ 15.0  │\n",
      "│ -2.79813  ┆ -2.852291 ┆ -2.848151 ┆ -0.888817 ┆ … ┆ -0.007277 ┆ 0.244642 ┆ 30.0  ┆ 15.0  │\n",
      "│ -2.88227  ┆ -2.787026 ┆ -2.989467 ┆ -0.990089 ┆ … ┆ -0.000877 ┆ 0.300377 ┆ 25.0  ┆ 15.0  │\n",
      "│ -2.940511 ┆ -2.963084 ┆ -2.917673 ┆ -1.102453 ┆ … ┆ 0.015277  ┆ 0.305211 ┆ 40.0  ┆ 15.0  │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …        ┆ …     ┆ …     │\n",
      "│ -3.133732 ┆ -3.183743 ┆ -3.048301 ┆ -1.128827 ┆ … ┆ 0.003632  ┆ 0.11048  ┆ 25.0  ┆ 18.0  │\n",
      "│ -2.90721  ┆ -2.749891 ┆ -3.00622  ┆ -0.902454 ┆ … ┆ 0.000624  ┆ 0.153394 ┆ 23.0  ┆ 18.0  │\n",
      "│ -2.789352 ┆ -2.862887 ┆ -2.860883 ┆ -0.847    ┆ … ┆ -0.000456 ┆ 0.074888 ┆ 30.0  ┆ 18.0  │\n",
      "│ -3.146779 ┆ -3.205947 ┆ -3.060043 ┆ -1.135908 ┆ … ┆ 0.001893  ┆ 0.05401  ┆ 40.0  ┆ 18.0  │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴──────────┴───────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Dataframe con 98 columnas\n",
    "# 16 primeras para las medias\n",
    "# 64 siguientes para los valores de las matrices de covarianza\n",
    "# Penúltima para el valor del OSNR (dB)\n",
    "# Última para el valor del espaciamiento (GHz)\n",
    "\n",
    "df_dict = {f\"col{n}\": [] for n in range(98)}\n",
    "\n",
    "# Iterate over the dictionary and populate the DataFrame\n",
    "for spacing, osnr in gaussians.items():\n",
    "    for osnr_, gmm_data in osnr.items():\n",
    "        gmm = gmm_data[0]\n",
    "        means = gmm.means_.flatten()\n",
    "        covariances = gmm.covariances_.flatten()\n",
    "        osnr_value = np.array([float(osnr_[:-2])])\n",
    "        spacing_value = np.array([float(spacing[:-11])])\n",
    "        \n",
    "        features = np.concatenate((means, covariances, osnr_value, spacing_value))\n",
    "        \n",
    "        for n in range(98):\n",
    "            df_dict[f\"col{n}\"].append(features[n])\n",
    "# Reset the index of the DataFrame\n",
    "df = pl.DataFrame(df_dict)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "df.write_json(\"histograms.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3e3092d5-50ab-4b42-9754-df1b1e139e31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (70, 98)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬──────────┬───────┬───────┐\n",
      "│ col0      ┆ col1      ┆ col2      ┆ col3      ┆ … ┆ col94     ┆ col95    ┆ col96 ┆ col97 │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---      ┆ ---   ┆ ---   │\n",
      "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64      ┆ f64   ┆ f64   │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪══════════╪═══════╪═══════╡\n",
      "│ -3.061791 ┆ -3.083884 ┆ -3.011383 ┆ -1.095477 ┆ … ┆ 0.003165  ┆ 0.263649 ┆ 35.0  ┆ 0.0   │\n",
      "│ -2.79813  ┆ -2.852291 ┆ -2.848151 ┆ -0.888817 ┆ … ┆ -0.007277 ┆ 0.244642 ┆ 30.0  ┆ 0.0   │\n",
      "│ -2.88227  ┆ -2.787026 ┆ -2.989467 ┆ -0.990089 ┆ … ┆ -0.000877 ┆ 0.300377 ┆ 25.0  ┆ 0.0   │\n",
      "│ -2.940511 ┆ -2.963084 ┆ -2.917673 ┆ -1.102453 ┆ … ┆ 0.015277  ┆ 0.305211 ┆ 40.0  ┆ 0.0   │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …        ┆ …     ┆ …     │\n",
      "│ -3.133732 ┆ -3.183743 ┆ -3.048301 ┆ -1.128827 ┆ … ┆ 0.003632  ┆ 0.11048  ┆ 25.0  ┆ 1.0   │\n",
      "│ -2.90721  ┆ -2.749891 ┆ -3.00622  ┆ -0.902454 ┆ … ┆ 0.000624  ┆ 0.153394 ┆ 23.0  ┆ 1.0   │\n",
      "│ -2.789352 ┆ -2.862887 ┆ -2.860883 ┆ -0.847    ┆ … ┆ -0.000456 ┆ 0.074888 ┆ 30.0  ┆ 1.0   │\n",
      "│ -3.146779 ┆ -3.205947 ┆ -3.060043 ┆ -1.135908 ┆ … ┆ 0.001893  ┆ 0.05401  ┆ 40.0  ┆ 1.0   │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴──────────┴───────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "interval_lst = [(0, 17.6), (17.6, 18)]\n",
    "df_2classes = classificator(df, interval_lst, \"col97\")\n",
    "print(df_2classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38d9a3-3269-48c2-bb1e-bced7d47341a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
