{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01441ee-fd0a-497c-9a2d-7dca25104e10",
   "metadata": {},
   "source": [
    "# Demodulación usando redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52bd51d-80dd-427d-a28f-1ca93b6321b2",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bae1c36-6bd6-42c6-b306-7b59124b0567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sofa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msofa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sofa'"
     ]
    }
   ],
   "source": [
    "import sofa\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# SciPy\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras import models, regularizers, utils\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from datetime.datetime import now\n",
    "\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e4612-ad50-4dd6-8d3b-4d69c1e839e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_GRID_KNN = {\"n_neighbors\": [3, 5, 7, 9, 11, 13, 15]}\n",
    "FIGSIZE = (16, 8)\n",
    "\n",
    "\n",
    "# Función especial para leer todos los datos con la estructura estudiada\n",
    "def read_data(folder_rx):\n",
    "    data = {}\n",
    "\n",
    "    # Leer la carpeta principal\n",
    "    for folder in os.listdir(folder_rx):\n",
    "        # Leer las subcarpetas\n",
    "        if folder.endswith(\"spacing\"):\n",
    "            data[folder] = {}\n",
    "            for file in os.listdir(f\"{folder_rx}/{folder}\"):\n",
    "                if file.find(\"consY\") != -1:\n",
    "                    data_name = file.split(\"_\")[2]\n",
    "                    if data[folder].get(data_name) == None:\n",
    "                        data[folder][data_name] = {}\n",
    "                    mat_file_data = loadmat(f\"{folder_rx}/{folder}/{file}\")\n",
    "                    data[folder][data_name] = mat_file_data\n",
    "    return data\n",
    "\n",
    "\n",
    "def classifier_model(layers_props_lst, loss_fn):\n",
    "    model = tf.keras.Sequential()\n",
    "    # Capas ocultas\n",
    "    for i, layer_props in enumerate(layers_props_lst):\n",
    "        if i == 0:\n",
    "            # 2 entradas, correspondientes a I, Q\n",
    "            model.add(ker.layers.Dense(**layer_props, input_dim=2))\n",
    "        else:\n",
    "            model.add(ker.layers.Dense(**layer_props))\n",
    "\n",
    "    # Clasificador\n",
    "    model.add(ker.layers.Dense(units=16, activation=\"softmax\"))\n",
    "\n",
    "    # Compilar modelo\n",
    "    model.compile(loss=loss_fn, optimizer=\"adam\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def demodulate_neural(X, y, layer_props_lst, loss_fn, train_size):\n",
    "    X = realify(X_rx)\n",
    "    y = sym_tx\n",
    "\n",
    "    X_train, _, y_train, _ = train_test_split(X, y, train_size=train_size)\n",
    "\n",
    "    # Modelo clasificador\n",
    "    model = classifier_model(layer_props_lst, loss_fn)\n",
    "    callback = EarlyStopping(\n",
    "        monitor=\"loss\", patience=300, mode=\"min\", restore_best_weights=True\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, y_train, epochs=5000, batch_size=64, verbose=0, callbacks=[callback]\n",
    "    )\n",
    "\n",
    "    return model.predict(X)\n",
    "\n",
    "\n",
    "# Función para demodular de manera tradicional, usando KNN y SVM\n",
    "def demodulation(X_rx, X_tx, train_size):\n",
    "    ber = {}\n",
    "\n",
    "    for i, snr in enumerate(X_rx):\n",
    "        # Extraer información\n",
    "        X_ch_norm = X_rx[snr].get(\"const_Y\").flatten()\n",
    "        X_ch = sofa.mod_norm(X_ch_norm, 10) * X_ch_norm\n",
    "\n",
    "        # Arreglos para el BER de cada algoritmo\n",
    "        trad_ber = np.empty(4)\n",
    "        knn_ber = np.empty(4)\n",
    "        neural_ber = np.empty(4)\n",
    "\n",
    "        for ph in range(4):\n",
    "            # Rotar constelación\n",
    "            rotated_X = X_ch * np.exp(ph * 1j * np.pi / 2)\n",
    "\n",
    "            # Sincronizar de las señales\n",
    "            synced_X_tx = sofa.sync_signals(X_tx, rotated_X)\n",
    "\n",
    "            # Demodular señal transmitida\n",
    "            y = sofa.demodulate(synced_X_tx, sofa.MOD_DICT)\n",
    "\n",
    "            # Mejores parámetros para los algoritmos\n",
    "            best_params_knn = sofa.find_best_params(\n",
    "                KNeighborsClassifier, PARAM_GRID_KNN, rotated_X, y\n",
    "            )\n",
    "            k = best_params_knn[\"n_neighbors\"]\n",
    "\n",
    "            max_neurons = 64\n",
    "            activations = [\"relu\", \"sigmoid\"]\n",
    "            layer_props = [\n",
    "                {\"units\": max_neurons // (2**i), \"activation\": activation}\n",
    "                for i, activation in enumerate(activations)\n",
    "            ]\n",
    "            loss_fn = tf.keras.losses.SparseCategoricalCrossentropy\n",
    "\n",
    "            # Demodulación\n",
    "            trad = sofa.demodulate(rotated_X, sofa.MOD_DICT)\n",
    "            knn = sofa.demodulate_knn(rotated_X, y, k=k, train_size=train_size)\n",
    "            neural = sofa.demodulate_neural(\n",
    "                rotated_X, y, layer_props, loss_fn, activations\n",
    "            )\n",
    "\n",
    "            # BER de la demodulación con respecto a la transmitida desplazada\n",
    "            # Índice 0 del retorno para tomar el BER e ignorar la cantidad de errores\n",
    "            trad_ber[ph] = sofa.bit_error_rate(trad, y)[0]\n",
    "            knn_ber[ph] = sofa.bit_error_rate(knn, y)[0]\n",
    "            neural_ber[ph] = sofa.bit_error_rate(neural, y)[0]\n",
    "\n",
    "        ber[snr] = {\n",
    "            \"trad\": np.amin(trad_ber),\n",
    "            \"knn\": np.amin(knn_ber),\n",
    "            \"neural\": np.amin(neural_ber),\n",
    "        }\n",
    "\n",
    "        # Mensaje para saber que se progresa\n",
    "        print(f\"SNR {snr[5:]} terminado.\")\n",
    "    return ber\n",
    "\n",
    "\n",
    "def curve_fit(f, x, y):\n",
    "    popt, pcov = sp.optimize.curve_fit(f, x, y)\n",
    "    return popt\n",
    "\n",
    "\n",
    "def spacing_ber_eval(ber, spacing):\n",
    "    print(\n",
    "        f\"Evaluación de la red neuronal con respecto a KNN para espaciamiento de {spacing} GHz\"\n",
    "    )\n",
    "\n",
    "    # Lista de strings con los SNR\n",
    "    SNR = [snr[5:-2] for snr in list(data[f\"{spacing}GHz_spacing\"].keys())]\n",
    "\n",
    "    SNR.sort()\n",
    "\n",
    "    get_ber = lambda algorithm: [\n",
    "        np.log10(ber.get(f\"consY{snr_i}dB\").get(algorithm)) for snr_i in SNR\n",
    "    ]\n",
    "    tBER = get_ber(\"trad\")\n",
    "    kBER = get_ber(\"knn\")\n",
    "    nBER = get_ber(\"neural\")\n",
    "\n",
    "    # Función para usar en la gráfica\n",
    "    f = lambda x, a, b, c: a * x**2 + b * x + c\n",
    "\n",
    "    # Arreglo con los SNR como flotantes\n",
    "    dSNR = np.array(SNR, dtype=np.float64)\n",
    "    xSNR = np.linspace(float(SNR[0]), float(SNR[-1]), 1000)\n",
    "\n",
    "    plt.rcParams[\"text.usetex\"] = True\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Tradicional: Brown\n",
    "    # KNN: Green\n",
    "    # Neural Network: Orange\n",
    "    plt.scatter(dSNR, tBER, marker=\"^\", c=\"brown\", label=\"Tradicional\")\n",
    "    plt.plot(\n",
    "        xSNR,\n",
    "        f(xSNR, *curve_fit(f, dSNR, tBER)),\n",
    "        c=\"brown\",\n",
    "        ls=\"dashed\",\n",
    "        label=\"Tradicional (fit)\",\n",
    "    )\n",
    "    plt.scatter(dSNR, kBER, marker=\"x\", c=\"green\", label=\"KNN\")\n",
    "    plt.plot(\n",
    "        xSNR,\n",
    "        f(xSNR, *curve_fit(f, dSNR, kBER)),\n",
    "        c=\"green\",\n",
    "        ls=\"dashed\",\n",
    "        label=\"KNN (fit)\",\n",
    "    )\n",
    "    plt.scatter(dSNR, nBER, marker=\"o\", c=\"orange\", label=\"Neural Network\")\n",
    "    plt.plot(\n",
    "        xSNR,\n",
    "        f(xSNR, *curve_fit(f, dSNR, nBER)),\n",
    "        c=\"orange\",\n",
    "        ls=\"dashed\",\n",
    "        label=\"Neural Network (fit)\",\n",
    "    )\n",
    "\n",
    "    plt.title(f\"{spacing} GHz spacing\")\n",
    "    plt.xlabel(\"OSNR (dB)\")\n",
    "    yticks = [f\"$10^{{{tick}}}$\" for tick in plt.yticks()]\n",
    "    plt.yticks(yticks)\n",
    "    plt.ylabel(\"BER\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calc_once(varname, fn, args):\n",
    "    \"\"\"Calcular una variable una sola vez.\"\"\"\n",
    "    if varname not in globals():\n",
    "        return fn(**args)\n",
    "    return eval(varname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d95b0f-e449-4f2d-a93e-0a9c8a3d1367",
   "metadata": {
    "id": "AZs5hIMpuIFG"
   },
   "source": [
    "## Datos experimentales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd2802c-d0da-4e66-bff9-f5ea9f6013d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "F2_5BERE2qJU",
    "outputId": "a304ca85-171f-4e4e-fff1-139cf18aecfb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_tx = \"Datos/2x16QAM_16GBd.mat\"\n",
    "folder_rx = \"Datos/\"\n",
    "\n",
    "# Datos transmitidos\n",
    "X_tx_norm = loadmat(file_tx)\n",
    "X_tx_norm = X_tx_norm.get(\"Constellation\").flatten()[0][0].flatten()\n",
    "X_tx = sofa.mod_norm(X_tx_norm, 10)*X_tx_norm\n",
    "\n",
    "# Leer los datos recibidos\n",
    "data = read_data(folder_rx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cec4e8c-b83c-46ae-bb95-0e5b4680676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: 2023-03-17 16:00:29.378404\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inicio: {now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac0a76-9a1c-4b0e-a7e1-26178c28b218",
   "metadata": {},
   "source": [
    "## Espaciamiento de 18 GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19adb319-225d-4413-a593-dd87bb3b6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = \"18\"\n",
    "\n",
    "neural_vs_knn_ber18 = calc_ber_once(spacing)\n",
    "\n",
    "%store neural_vs_knn_ber18\n",
    "\n",
    "spacing_ber_eval(neural_vs_knn_ber18, spacing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
